{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to create a rainfall-runoff model using data driven methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Description**\n",
    "\n",
    "The following notebook contains the code to create, train, validate, and test a rainfall-runoff model using a Hybrid Hydrological approach. We use an LSTM network to parameterize a process based rainfall-runoff model. The code allows for the creation of single-basin models, but it is conceptualized to create regional models. The code is intended as an intial introduction to the topic, \n",
    "in which we prioritized interpretability over modularity.\n",
    "\n",
    "The logic of the code is heavily based on [Neural Hydrology](https://doi.org/10.21105/joss.04050) [1]. For a more flexible, robust, and modular implementation of deep learning methods in hydrological modeling, we advise the use of Neural Hydrology. \n",
    "\n",
    "**Experiment Details**\n",
    "- In this example we use the Hybrid model architecture, to create a regional rainfall-runoff model for 531 basins of the CAMELS_US dataset [2], [3].\n",
    "\n",
    "**Authors:**\n",
    "- Eduardo Acuña Espinoza (eduardo.espinoza@kit.edu)\n",
    "- Ralf Loritz\n",
    "- Manuel Álvarez Chaves\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1]: Kratzert, F., Gauch, M., Nearing, G., & Klotz, D. (2022). NeuralHydrology – A Python library for deep learning research in hydrology. Journal of Open Source Software, 7, 4050. https://doi.org/10.21105/joss.04050\n",
    "\n",
    "[2]: Newman, A. J., Clark, M. P., Sampson, K., Wood, A., Hay, L. E., Bock, A., Viger, R. J., Blodgett, D., Brekke, L., Arnold, J. R., Hopson, T., & Duan, Q. (2015). Development of a large-sample watershed-scale hydrometeorological dataset for the contiguous USA: dataset characteristics and assessment of regional variability in hydrologic model performance. *Hydrology and Earth System Sciences, 19*, 209-223. https://doi.org/10.5194/hess-19-209-2015\n",
    "\n",
    "[3]: Addor, N., Newman, A. J., Mizukami, N., & Clark, M. P. (2017). The CAMELS data set: catchment attributes and meteorology for large-sample studies. *Hydrology and Earth System Sciences, 21*, 5293-5313. https://doi.org/10.5194/hess-21-5293-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "# Import classes and functions from other files\n",
    "from hy2dl.aux_functions.functions_evaluation import nse\n",
    "from hy2dl.aux_functions.functions_training import nse_basin_averaged, weighted_rmse\n",
    "from hy2dl.aux_functions.utils import Optimizer, create_folder, set_random_seed, upload_to_device, write_report\n",
    "from hy2dl.datasetzoo.camelsus import CAMELS_US as Datasetclass\n",
    "from hy2dl.modelzoo.hbv import HBV as conceptual_model\n",
    "from hy2dl.modelzoo.hybrid import Hybrid as modelclass\n",
    "from hy2dl.modelzoo.uh_routing import UH_routing as routing_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1. Initialize information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment nae\n",
    "experiment_name = \"Hybrid_CAMELS_US\"\n",
    "\n",
    "# paths to access the information\n",
    "path_entities = \"../data/basin_id/basins_camels_us_531.txt\"\n",
    "path_data = \"../data/CAMELS_US\"\n",
    "path_additional_features = \"../data/CAMELS_US/pet_hargreaves.pickle\"\n",
    "\n",
    "# dynamic forcings and target\n",
    "dynamic_input = [\"prcp(mm/day)\", \"srad(W/m2)\", \"tmax(C)\", \"tmin(C)\", \"vp(Pa)\", \"dayl(s)\"]\n",
    "conceptual_input = [\"prcp(mm/day)\", \"pet(mm/day)\", \"tmax(C)\", \"tmin(C)\"]\n",
    "forcing = [\"daymet\"]\n",
    "target = [\"QObs(mm/d)\"]\n",
    "\n",
    "# static attributes that will be used. If one is not using static_inputs, initialize the variable as an empty list.\n",
    "static_input = [\n",
    "    \"p_mean\",\n",
    "    \"pet_mean\",\n",
    "    \"p_seasonality\",\n",
    "    \"frac_snow\",\n",
    "    \"aridity\",\n",
    "    \"high_prec_freq\",\n",
    "    \"high_prec_dur\",\n",
    "    \"low_prec_freq\",\n",
    "    \"low_prec_dur\",\n",
    "    \"elev_mean\",\n",
    "    \"slope_mean\",\n",
    "    \"area_gages2\",\n",
    "    \"frac_forest\",\n",
    "    \"lai_max\",\n",
    "    \"lai_diff\",\n",
    "    \"gvf_max\",\n",
    "    \"gvf_diff\",\n",
    "    \"dom_land_cover_frac\",\n",
    "    \"dom_land_cover\",\n",
    "    \"root_depth_50\",\n",
    "    \"soil_depth_pelletier\",\n",
    "    \"soil_depth_statsgo\",\n",
    "    \"soil_porosity\",\n",
    "    \"soil_conductivity\",\n",
    "    \"max_water_content\",\n",
    "    \"sand_frac\",\n",
    "    \"silt_frac\",\n",
    "    \"clay_frac\",\n",
    "    \"geol_1st_class\",\n",
    "    \"glim_1st_class_frac\",\n",
    "    \"geol_2nd_class\",\n",
    "    \"glim_2nd_class_frac\",\n",
    "    \"carbonate_rocks_frac\",\n",
    "    \"geol_porostiy\",\n",
    "    \"geol_permeability\",\n",
    "]\n",
    "\n",
    "# time periods\n",
    "training_period = [\"1980-10-01\", \"1995-09-30\"]\n",
    "validation_period = [\"1980-12-31\", \"1985-09-30\"] #1980-12-31 - 365 = 1980-01-01\n",
    "testing_period = [\"1995-10-01\", \"2010-09-30\"]\n",
    "\n",
    "\n",
    "# model configuration\n",
    "model_configuration = {\n",
    "    \"input_size_lstm\": len(dynamic_input) + len(static_input),\n",
    "    \"no_of_layers\": 1,\n",
    "    \"seq_length\": 730,\n",
    "    \"predict_last_n\": 365,\n",
    "    \"unique_prediction_blocks\": False,\n",
    "    \"hidden_size\": 256,\n",
    "    \"conceptual_model\": conceptual_model,\n",
    "    \"routing_model\": routing_model,\n",
    "    \"batch_size_training\": 256,\n",
    "    \"batch_size_evaluation\": 100,  # number of basins that will be run for the whole period\n",
    "    \"no_of_epochs\": 20,\n",
    "    \"max_updates_per_epoch\": 450,\n",
    "    \"learning_rate\": {1: 1e-3, 10: 5e-4, 20: 1e-4},\n",
    "    \"set_forget_gate\": 3,\n",
    "    \"n_conceptual_models\": 16,\n",
    "    \"conceptual_dynamic_parameterization\": [\"BETA\", \"BETAET\"],\n",
    "    \"validate_every\": 4,\n",
    "}\n",
    "\n",
    "# device to train the model\n",
    "running_device = \"gpu\"  # cpu or gpu\n",
    "\n",
    "# define random seed\n",
    "seed = 111111\n",
    "\n",
    "# colorblind friendly palette\n",
    "color_palette = {\"observed\": \"#377eb8\",\"simulated\": \"#4daf4a\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2. Calculate additional information necessary to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to store the results\n",
    "path_save_folder = \"../results/\" + experiment_name + \"_seed_\" + str(seed)\n",
    "create_folder(folder_path=path_save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if model will be run in gpu or cpu and define device\n",
    "if running_device == \"gpu\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = \"cuda:0\"\n",
    "elif running_device == \"cpu\":\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3. Class to create the dataset object used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset training\n",
    "training_dataset = Datasetclass(\n",
    "    dynamic_input=dynamic_input,\n",
    "    forcing=forcing,\n",
    "    target=target,\n",
    "    sequence_length=model_configuration[\"seq_length\"],\n",
    "    time_period=training_period,\n",
    "    path_data=path_data,\n",
    "    path_entities=path_entities,\n",
    "    path_additional_features=path_additional_features,\n",
    "    check_NaN=True,\n",
    "    predict_last_n=model_configuration[\"predict_last_n\"],\n",
    "    static_input=static_input,\n",
    "    conceptual_input=conceptual_input,\n",
    "    unique_prediction_blocks=model_configuration[\"unique_prediction_blocks\"],\n",
    ")\n",
    "\n",
    "training_dataset.calculate_basin_std()\n",
    "training_dataset.calculate_global_statistics(path_save_scaler=path_save_folder)\n",
    "training_dataset.standardize_data(standardize_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader training\n",
    "train_loader = DataLoader(\n",
    "    dataset=training_dataset,\n",
    "    batch_size=model_configuration[\"batch_size_training\"],\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    collate_fn=training_dataset.collate_fn,\n",
    ")\n",
    "\n",
    "# Print details of a loader´s sample to see that our format is correct\n",
    "print(\"Number of batches in training: \", len(train_loader))\n",
    "print(\"\\nSample batch details:\")\n",
    "print(f\"{'Key':<12} | {'Shape':<20}\")\n",
    "print(\"-\" * 35)\n",
    "# Loop through the sample dictionary and print the shape of each element\n",
    "for key, value in next(iter(train_loader)).items():\n",
    "    print(f\"{key:<12} | {str(value.shape):<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4. Create dataset for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we run our evalation period (validation or testing), we want to differentiate between basins. Therefore, each \n",
    "# batch entity will contain the whole time period (validation or testing) of a specific basin. For this, we will modify \n",
    "# seq_length and the predict_last_n.\n",
    "warmup_start_date = pd.to_datetime(validation_period[0], format=\"%Y-%m-%d\") - pd.DateOffset(\n",
    "    model_configuration[\"seq_length\"] - model_configuration[\"predict_last_n\"]\n",
    ")\n",
    "evaluation_seq_length = (pd.to_datetime(validation_period[1], format=\"%Y-%m-%d\") - warmup_start_date).days + 1\n",
    "evaluation_predict_last_n = evaluation_seq_length - model_configuration[\"predict_last_n\"]\n",
    "\n",
    "validation_dataset = Datasetclass(\n",
    "    dynamic_input=dynamic_input,\n",
    "    forcing=forcing,\n",
    "    target=target,\n",
    "    sequence_length=evaluation_seq_length,\n",
    "    time_period=validation_period,\n",
    "    path_data=path_data,\n",
    "    path_entities=path_entities,\n",
    "    path_additional_features=path_additional_features,\n",
    "    check_NaN=False,\n",
    "    predict_last_n=evaluation_predict_last_n,\n",
    "    static_input=static_input,\n",
    "    conceptual_input=conceptual_input,\n",
    ")\n",
    "\n",
    "validation_dataset.scaler = training_dataset.scaler  # read the global statistics calculated in the training period\n",
    "validation_dataset.standardize_data(standardize_output=False)\n",
    "\n",
    "# DataLoader testing\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=model_configuration[\"batch_size_training\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=training_dataset.collate_fn,\n",
    ")\n",
    "\n",
    "# Print details of a loader´s sample to see that our format is correct\n",
    "print(\"Number of batches in validation: \", len(validation_loader))\n",
    "print(\"\\nSample batch details:\")\n",
    "print(f\"{'Key':<12} | {'Shape':<20}\")\n",
    "print(\"-\" * 35)\n",
    "# Loop through the sample dictionary and print the shape of each element\n",
    "for key, value in next(iter(validation_loader)).items():\n",
    "    print(f\"{key:<12} | {str(value.shape):<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "set_random_seed(seed=seed)\n",
    "model = modelclass(model_configuration=model_configuration).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = Optimizer(model=model, model_configuration=model_configuration) \n",
    "\n",
    "# set forget gate to 3 to ensure that the model is capable to learn long term dependencies\n",
    "model.lstm.bias_hh_l0.data[model_configuration[\"hidden_size\"] : 2 * model_configuration[\"hidden_size\"]] = (\n",
    "    model_configuration[\"set_forget_gate\"]\n",
    ")\n",
    "\n",
    "training_time = time.time()\n",
    "# Loop through the different epochs\n",
    "for epoch in range(1, model_configuration[\"no_of_epochs\"] + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    total_loss = []\n",
    "    # Training -------------------------------------------------------------------------------------------------------\n",
    "    model.train()\n",
    "    for idx, sample in enumerate(train_loader):\n",
    "        # maximum iterations per epoch\n",
    "        if (\n",
    "            model_configuration.get(\"max_updates_per_epoch\") is not None\n",
    "            and idx >= model_configuration[\"max_updates_per_epoch\"]\n",
    "        ):\n",
    "            break\n",
    "\n",
    "        sample = upload_to_device(sample, device)  # upload tensors to device\n",
    "        optimizer.optimizer.zero_grad()  # sets gradients of weigths and bias to zero\n",
    "\n",
    "        pred = model(sample)  # forward call\n",
    "\n",
    "        loss = nse_basin_averaged(y_sim=pred[\"y_hat\"], y_obs=sample[\"y_obs\"], per_basin_target_std=sample[\"basin_std\"])\n",
    "\n",
    "        loss.backward()  # backpropagates\n",
    "        \n",
    "        optimizer.clip_grad_and_step(epoch, idx) # clip gradients and update weights\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        # remove from cuda\n",
    "        del sample, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # training report\n",
    "    report = f'Epoch: {epoch:<2} | Loss training: {\"%.3f \"% (np.mean(total_loss))}'\n",
    "\n",
    "    # Validation -----------------------------------------------------------------------------------------------------\n",
    "    if epoch % model_configuration[\"validate_every\"] == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            validation_results = {}\n",
    "            for sample in validation_loader:\n",
    "                sample = upload_to_device(sample, device)  # upload tensors to device\n",
    "                pred = model(sample)  # forward call # forward call\n",
    "\n",
    "                # join results in a dataframe and store them in a dictionary (is easier to plot later)\n",
    "                for i in range(pred[\"y_hat\"].shape[0]):\n",
    "                    df_discharge = pd.DataFrame(\n",
    "                        data={\n",
    "                            \"y_obs\": sample[\"y_obs\"][i, :, 0].flatten().cpu().detach().numpy(),\n",
    "                            \"y_sim\": pred[\"y_hat\"][i, :, 0].flatten().cpu().detach().numpy(),\n",
    "                        },\n",
    "                        index=pd.to_datetime(sample[\"date\"][i, :].flatten()),\n",
    "                    )\n",
    "\n",
    "                    validation_results[sample[\"basin\"][i]] = df_discharge\n",
    "\n",
    "                # remove from cuda\n",
    "                del sample, pred\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # average loss validation\n",
    "        loss_validation = nse(df_results=validation_results)\n",
    "        report += f'| NSE validation: {\"%.3f \"% (loss_validation)}'\n",
    "\n",
    "    # save model after every epoch\n",
    "    path_saved_model = path_save_folder + \"/epoch_\" + str(epoch)\n",
    "    torch.save(model.state_dict(), path_saved_model)\n",
    "\n",
    "    # print epoch report\n",
    "    report += (\n",
    "        f'| Epoch time: {\"%.1f \"% (time.time()-epoch_start_time)} s | '\n",
    "        f'LR:{\"%.5f \"% (optimizer.optimizer.param_groups[0][\"lr\"])}'\n",
    "    )\n",
    "    print(report)\n",
    "    write_report(file_path=path_save_folder + \"/run_progress.txt\", text=report)\n",
    "    # modify learning rate\n",
    "    optimizer.update_optimizer_lr(epoch=epoch)\n",
    "\n",
    "# print final report\n",
    "report = f'Total training time: {\"%.1f \"% (time.time()-training_time)} s'\n",
    "print(report)\n",
    "write_report(file_path=path_save_folder + \"/run_progress.txt\", text=report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 6. Test LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case I already trained an LSTM I can re-construct the model\n",
    "# model = modelclass(model_configuration=model_configuration).to(device)\n",
    "# model.load_state_dict(torch.load(path_save_folder + \"/epoch_20\", map_location=device))\n",
    "\n",
    "# We can read the training scaler or read a previously stored one\n",
    "scaler = training_dataset.scaler\n",
    "# with open(path_save_folder + \"/scaler.pickle\", \"rb\") as file:\n",
    "#    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we run our evalation period (validation or testing), we want to differentiate between basins. Therefore, each \n",
    "# batch entity will contain the whole time period (validation or testing) of a specific basin. For this, we will modify \n",
    "# seq_length and the predict_last_n.\n",
    "warmup_start_date = pd.to_datetime(testing_period[0], format=\"%Y-%m-%d\") - pd.DateOffset(\n",
    "    model_configuration[\"seq_length\"] - model_configuration[\"predict_last_n\"]\n",
    ")\n",
    "evaluation_seq_length = (pd.to_datetime(testing_period[1], format=\"%Y-%m-%d\") - warmup_start_date).days + 1\n",
    "evaluation_predict_last_n = evaluation_seq_length - model_configuration[\"predict_last_n\"]\n",
    "\n",
    "testing_dataset = Datasetclass(\n",
    "    dynamic_input=dynamic_input,\n",
    "    forcing=forcing,\n",
    "    target=target,\n",
    "    sequence_length=evaluation_seq_length,\n",
    "    time_period=testing_period,\n",
    "    path_data=path_data,\n",
    "    path_entities=path_entities,\n",
    "    path_additional_features=path_additional_features,\n",
    "    check_NaN=False,\n",
    "    predict_last_n=evaluation_predict_last_n,\n",
    "    static_input=static_input,\n",
    "    conceptual_input=conceptual_input,\n",
    ")\n",
    "\n",
    "testing_dataset.scaler = scaler  # read the global statistics calculated in the training period\n",
    "testing_dataset.standardize_data(standardize_output=False)\n",
    "\n",
    "# DataLoader testing\n",
    "test_loader = DataLoader(\n",
    "    testing_dataset,\n",
    "    batch_size=model_configuration[\"batch_size_training\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=training_dataset.collate_fn,\n",
    ")\n",
    "\n",
    "# Print details of a loader´s sample to see that our format is correct\n",
    "print(\"Number of batches in testing: \", len(test_loader))\n",
    "print(\"\\nSample batch details:\")\n",
    "print(f\"{'Key':<12} | {'Shape':<20}\")\n",
    "print(\"-\" * 35)\n",
    "# Loop through the sample dictionary and print the shape of each element\n",
    "for key, value in next(iter(test_loader)).items():\n",
    "    print(f\"{key:<12} | {str(value.shape):<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing ----------------------------------------------------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_results = {}\n",
    "    for sample in test_loader:\n",
    "        sample = upload_to_device(sample, device)  # upload tensors to device\n",
    "        pred = model(sample)  # forward call\n",
    "\n",
    "        # join results in a dataframe and store them in a dictionary (is easier to plot later)\n",
    "        for i in range(pred[\"y_hat\"].shape[0]):\n",
    "            df_discharge = pd.DataFrame(\n",
    "                data={\n",
    "                    \"y_obs\": sample[\"y_obs\"][i, :, 0].flatten().cpu().detach().numpy(),\n",
    "                    \"y_sim\": pred[\"y_hat\"][i, :, 0].flatten().cpu().detach().numpy(),\n",
    "                },\n",
    "                index=pd.to_datetime(sample[\"date\"][i, :].flatten()),\n",
    "            )\n",
    "\n",
    "            # extract internal_state (buckets) information\n",
    "            internal_states = {\n",
    "                key: value[i, :, :].squeeze(0).cpu().detach().numpy() for key, value in pred[\"internal_states\"].items()\n",
    "            }\n",
    "\n",
    "            # extract parameter  information\n",
    "            parameters = {\n",
    "                key: value[i, :, :].squeeze(0).cpu().detach().numpy() for key, value in pred[\"parameters\"].items()\n",
    "            }\n",
    "\n",
    "            test_results[sample[\"basin\"][i]] = {\n",
    "                \"discharges\": df_discharge,\n",
    "                \"internal_states\": internal_states,\n",
    "                \"parameters\": parameters,\n",
    "            }\n",
    "\n",
    "        # remove from cuda\n",
    "        del sample, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Save results as a pickle file\n",
    "with open(path_save_folder+\"/test_results.pickle\", \"wb\") as f:\n",
    "   pickle.dump(test_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 7. Initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharges = {key: value[\"discharges\"] for key, value in test_results.items()}\n",
    "loss_testing = nse(df_results=discharges, average=False)\n",
    "df_NSE = pd.DataFrame(data={\"basin_id\": list(test_results.keys()), \"NSE\": np.round(loss_testing, 3)})\n",
    "df_NSE = df_NSE.set_index(\"basin_id\")\n",
    "df_NSE.to_csv(path_save_folder + \"/NSE.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "plt.hist(df_NSE[\"NSE\"], bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "# Add NSE statistics to the plot\n",
    "plt.text(\n",
    "    0.01,\n",
    "    0.8,\n",
    "    (\n",
    "        f'Mean: {\"%.2f\" % df_NSE[\"NSE\"].mean():>7}\\n'\n",
    "        f'Median: {\"%.2f\" % df_NSE[\"NSE\"].median():>0}\\n'\n",
    "        f'Max: {\"%.2f\" % df_NSE[\"NSE\"].max():>9}\\n'\n",
    "        f'Min: {\"%.2f\" % df_NSE[\"NSE\"].min():>10}'\n",
    "    ),\n",
    "    transform=plt.gca().transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "\n",
    "# Format plot\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "plt.xlabel(\"NSE\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Frequency\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"NSE Histogram\", fontsize=16, fontweight=\"bold\")\n",
    "# plt.savefig(save_folder+\"/NSE_Histogram.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulated and observed discharges\n",
    "basin_to_analyze = \"01022500\"\n",
    "plt.plot(test_results[basin_to_analyze][\"discharges\"][\"y_obs\"], label=\"observed\", color=color_palette[\"observed\"])\n",
    "plt.plot(\n",
    "    test_results[basin_to_analyze][\"discharges\"][\"y_sim\"],\n",
    "    label=\"simulated\",\n",
    "    alpha=0.5,\n",
    "    color=color_palette[\"simulated\"],\n",
    ")\n",
    "\n",
    "# Format plot\n",
    "plt.xlabel(\"Day\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Discharge [mm/d]\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"Discharge comparison\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)\n",
    "# plt.savefig(save_folder+\"/Model_Comparison.png\", bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot states\n",
    "state_of_interest = \"SM\"\n",
    "\n",
    "states = test_results[basin_to_analyze][\"internal_states\"][state_of_interest]\n",
    "\n",
    "for i in range(states.shape[1]):\n",
    "    plt.plot(\n",
    "        test_results[basin_to_analyze][\"discharges\"][\"y_obs\"].index,\n",
    "        states[:, i],\n",
    "        label=state_of_interest + \"_\" + str(i + 1),\n",
    "    )\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel(\"Day\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"State [mm/d]\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"Time evolution of internal states of conceptual model\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot states\n",
    "parameter_of_interest = \"BETA\"\n",
    "\n",
    "states = test_results[basin_to_analyze][\"parameters\"][parameter_of_interest]\n",
    "\n",
    "for i in range(states.shape[1]):\n",
    "    plt.plot(\n",
    "        test_results[basin_to_analyze][\"discharges\"][\"y_obs\"].index,\n",
    "        states[:, i],\n",
    "        label=parameter_of_interest + \"_\" + str(i + 1),\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel(\"Day\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"State [mm/d]\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"Time evolution of parameters of conceptual model\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m111"
  },
  "kernelspec": {
   "display_name": "env_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
