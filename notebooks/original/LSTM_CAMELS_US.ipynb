{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to create a rainfall-runoff model using data driven methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Description**\n",
    "\n",
    "The following notebook contains the code to create, train, validate, and test a rainfall-runoff model using an LSTM network architecture. The code allows for the creation of single-basin models but is conceptualized to create regional models. The code is intended as an initial introduction to the topic, prioritizing interpretability over modularity.\n",
    "\n",
    "The logic of the code is heavily based on [Neural Hydrology](https://doi.org/10.21105/joss.04050) [1]. For a more flexible, robust, and modular implementation of deep learning methods in hydrological modeling, we advise the use of Neural Hydrology. \n",
    "\n",
    "**Experiment Details**\n",
    "- In this example, we use the LSTM architecture to create a regional rainfall-runoff model for 531 basins of the CAMELS_US dataset [2], [3]. \n",
    "- The setup of the experiment is based on [4].\n",
    "\n",
    "**Authors:**\n",
    "- Eduardo Acuña Espinoza (eduardo.espinoza@kit.edu)\n",
    "- Ralf Loritz\n",
    "- Manuel Álvarez Chaves\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1]: Kratzert, F., Gauch, M., Nearing, G., & Klotz, D. (2022). NeuralHydrology – A Python library for deep learning research in hydrology. Journal of Open Source Software, 7, 4050. https://doi.org/10.21105/joss.04050\n",
    "\n",
    "[2]: Newman, A. J., Clark, M. P., Sampson, K., Wood, A., Hay, L. E., Bock, A., Viger, R. J., Blodgett, D., Brekke, L., Arnold, J. R., Hopson, T., & Duan, Q. (2015). Development of a large-sample watershed-scale hydrometeorological dataset for the contiguous USA: dataset characteristics and assessment of regional variability in hydrologic model performance. *Hydrology and Earth System Sciences, 19*, 209-223. https://doi.org/10.5194/hess-19-209-2015\n",
    "\n",
    "[3]: Addor, N., Newman, A. J., Mizukami, N., & Clark, M. P. (2017). The CAMELS data set: catchment attributes and meteorology for large-sample studies. *Hydrology and Earth System Sciences, 21*, 5293-5313. https://doi.org/10.5194/hess-21-5293-2017\n",
    "\n",
    "[4]: Kratzert, F., Klotz, D., Shalev, G., Klambauer, G., Hochreiter, S., & Nearing, G. (2019). Towards learning universal, regional, and local hydrological behaviors via machine learning applied to large-sample datasets. *Hydrology and Earth System Sciences, 23*(12), 5089–5110. https://doi.org/10.5194/hess-23-5089-2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "# Import classes and functions from other files\n",
    "from hy2dl.aux_functions.functions_evaluation import nse\n",
    "from hy2dl.aux_functions.functions_training import nse_basin_averaged\n",
    "from hy2dl.aux_functions.utils import Optimizer, create_folder, set_random_seed, upload_to_device, write_report\n",
    "from hy2dl.datasetzoo.camelsus import CAMELS_US as Datasetclass\n",
    "from hy2dl.modelzoo.cudalstm import CudaLSTM as modelclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1. Initialize information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment nae\n",
    "experiment_name = \"LSTM_CAMELS_US\"\n",
    "\n",
    "# paths to access the information\n",
    "path_entities = \"../data/basin_id/basins_camels_us_531.txt\"\n",
    "path_data = \"../data/CAMELS_US\"\n",
    "\n",
    "# dynamic forcings and target\n",
    "dynamic_input = [\"prcp(mm/day)\", \"srad(W/m2)\", \"tmax(C)\", \"tmin(C)\", \"vp(Pa)\"]\n",
    "forcing = [\"daymet\"]\n",
    "target = [\"QObs(mm/d)\"]\n",
    "\n",
    "# static attributes that will be used. If one is not using static_inputs, initialize the variable as an empty list.\n",
    "static_input = [\n",
    "    \"elev_mean\",\n",
    "    \"slope_mean\",\n",
    "    \"area_gages2\",\n",
    "    \"frac_forest\",\n",
    "    \"lai_max\",\n",
    "    \"lai_diff\",\n",
    "    \"gvf_max\",\n",
    "    \"gvf_diff\",\n",
    "    \"soil_depth_pelletier\",\n",
    "    \"soil_depth_statsgo\",\n",
    "    \"soil_porosity\",\n",
    "    \"soil_conductivity\",\n",
    "    \"max_water_content\",\n",
    "    \"sand_frac\",\n",
    "    \"silt_frac\",\n",
    "    \"clay_frac\",\n",
    "    \"carbonate_rocks_frac\",\n",
    "    \"geol_permeability\",\n",
    "    \"p_mean\",\n",
    "    \"pet_mean\",\n",
    "    \"p_seasonality\",\n",
    "    \"aridity\",\n",
    "    \"frac_snow\",\n",
    "    \"high_prec_freq\",\n",
    "    \"high_prec_dur\",\n",
    "    \"low_prec_freq\",\n",
    "    \"low_prec_dur\",\n",
    "]\n",
    "\n",
    "# time periods\n",
    "training_period = [\"1999-10-01\", \"2008-09-30\"]\n",
    "validation_period = [\"1980-10-01\", \"1989-09-30\"]\n",
    "testing_period = [\"1989-10-01\", \"1999-10-30\"]\n",
    "\n",
    "# model configuration\n",
    "model_configuration = {\n",
    "    \"n_dynamic_channels_lstm\": len(dynamic_input),\n",
    "    \"no_of_layers\": 1,\n",
    "    \"seq_length\": 365,\n",
    "    \"hidden_size\": 128,\n",
    "    \"batch_size_training\": 256,\n",
    "    \"batch_size_evaluation\": 1024,\n",
    "    \"no_of_epochs\": 30,\n",
    "    \"dropout_rate\": 0.4,\n",
    "    \"learning_rate\": {1: 1e-3, 10: 5e-4, 20: 1e-4},\n",
    "    \"set_forget_gate\": 3,\n",
    "    \"validate_every\": 5,\n",
    "    \"validate_n_random_basins\": -1,\n",
    "}\n",
    "\n",
    "# device to train the model\n",
    "running_device = \"gpu\"  # cpu or gpu\n",
    "\n",
    "# define random seed\n",
    "seed = 110\n",
    "\n",
    "# colorblind friendly palette\n",
    "color_palette = {\"observed\": \"#377eb8\",\"simulated\": \"#4daf4a\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2. Calculate additional information necessary to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to store the results\n",
    "path_save_folder = \"../results/\" + experiment_name + \"_seed_\" + str(seed)\n",
    "create_folder(folder_path=path_save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if model will be run in gpu or cpu and define device\n",
    "if running_device == \"gpu\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = \"cuda:0\"\n",
    "elif running_device == \"cpu\":\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include information about input size for each frequency\n",
    "if isinstance(dynamic_input, list):\n",
    "    model_configuration[\"dynamic_input_size\"] = len(dynamic_input)\n",
    "elif isinstance(dynamic_input, dict):\n",
    "    model_configuration[\"dynamic_input_size\"] = {key: len(value) for key, value in dynamic_input.items()}\n",
    "\n",
    "# include information about input size for lstm\n",
    "model_configuration[\"input_size_lstm\"] = model_configuration[\"n_dynamic_channels_lstm\"] + len(static_input)\n",
    "\n",
    "# if I am processing multiple frequencies and do not have custom dynamic embeddings for each frequency, I add an\n",
    "# additional channel that will be used as a flag to indicate the frequency.\n",
    "if model_configuration.get(\"custom_freq_processing\") and not model_configuration.get(\"dynamic_embeddings\"):\n",
    "    model_configuration[\"input_size_lstm\"] = model_configuration[\"input_size_lstm\"] + 1\n",
    "\n",
    "# If predict_last_n was not defined, we initialize it as 1\n",
    "if not model_configuration.get(\"predict_last_n\"):\n",
    "    model_configuration[\"predict_last_n\"] = 1\n",
    "\n",
    "# Check connection between predict_last_n and unique_prediction_blocks. If predict_last_n is larger than 1, and\n",
    "# unique_prediction_blocks is False, we change for evaluation purposes predict_last_n to 1. This avoid having\n",
    "# multiple predictions for the same time step due to the overlap of the sequences.\n",
    "if model_configuration.get(\"predict_last_n\", 1) > 1 and not model_configuration.get(\"unique_prediction_blocks\"):\n",
    "    print(\n",
    "        (\n",
    "            \"Warning: predict_last_n > 1 and unique_prediction_blocks = False.\"\n",
    "            + \" This creates overlapping sequences during evaluation. To avoid this, predict_last_n will be changed to\"\n",
    "            + \" 1 during evaluation (validation / testing). This will not affect the training process.\"\n",
    "        )\n",
    "    )\n",
    "    model_configuration[\"predict_last_n_evaluation\"] = 1\n",
    "else:\n",
    "    model_configuration[\"predict_last_n_evaluation\"] = model_configuration.get(\"predict_last_n\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3. Class to create the dataset object used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset training\n",
    "training_dataset = Datasetclass(\n",
    "    dynamic_input=dynamic_input,\n",
    "    forcing=forcing,\n",
    "    target=target,\n",
    "    sequence_length=model_configuration[\"seq_length\"],\n",
    "    time_period=training_period,\n",
    "    path_data=path_data,\n",
    "    path_entities=path_entities,\n",
    "    check_NaN=True,\n",
    "    static_input=static_input,\n",
    ")\n",
    "\n",
    "training_dataset.calculate_basin_std()\n",
    "training_dataset.calculate_global_statistics(path_save_scaler=path_save_folder)\n",
    "training_dataset.standardize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader training\n",
    "train_loader = DataLoader(\n",
    "    dataset=training_dataset,\n",
    "    batch_size=model_configuration[\"batch_size_training\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=training_dataset.collate_fn,\n",
    ")\n",
    "\n",
    "# Print details of a loader´s sample to see that our format is correct\n",
    "print(\"Number of batches in training: \", len(train_loader))\n",
    "print(\"\\nSample batch details:\")\n",
    "print(f\"{'Key':<12} | {'Shape':<20}\")\n",
    "print(\"-\" * 35)\n",
    "# Loop through the sample dictionary and print the shape of each element\n",
    "for key, value in next(iter(train_loader)).items():\n",
    "    print(f\"{key:<12} | {str(value.shape):<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4. Create dataset for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In evaluation (validation and testing) we will create an individual dataset per basin. This will give us more \n",
    "# flexibility\n",
    "entities_ids = np.loadtxt(path_entities, dtype=\"str\").tolist()\n",
    "entities_ids = [entities_ids] if isinstance(entities_ids, str) else entities_ids\n",
    "validation_dataset = {}\n",
    "for entity in entities_ids:\n",
    "    dataset = Datasetclass(\n",
    "        dynamic_input=dynamic_input,\n",
    "        forcing=forcing,\n",
    "        target=target,\n",
    "        sequence_length=model_configuration[\"seq_length\"],\n",
    "        time_period=validation_period,\n",
    "        path_data=path_data,\n",
    "        entity=entity,\n",
    "        check_NaN=False,\n",
    "        static_input=static_input,\n",
    "    )\n",
    "\n",
    "    dataset.scaler = training_dataset.scaler\n",
    "    dataset.standardize_data(standardize_output=False)\n",
    "    validation_dataset[entity] = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "set_random_seed(seed=seed)\n",
    "model = modelclass(model_configuration=model_configuration).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = Optimizer(model=model, model_configuration=model_configuration) \n",
    "\n",
    "# set forget gate to 3 to ensure that the model is capable to learn long term dependencies\n",
    "model.lstm.bias_hh_l0.data[model_configuration[\"hidden_size\"] : 2 * model_configuration[\"hidden_size\"]] = (\n",
    "    model_configuration[\"set_forget_gate\"]\n",
    ")\n",
    "\n",
    "training_time = time.time()\n",
    "# Loop through the different epochs\n",
    "for epoch in range(1, model_configuration[\"no_of_epochs\"] + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    total_loss = []\n",
    "    # Training -------------------------------------------------------------------------------------------------------\n",
    "    model.train()\n",
    "    for idx, sample in enumerate(train_loader):\n",
    "        # maximum iterations per epoch\n",
    "        if (\n",
    "            model_configuration.get(\"max_updates_per_epoch\") is not None\n",
    "            and idx >= model_configuration[\"max_updates_per_epoch\"]\n",
    "        ):\n",
    "            break\n",
    "\n",
    "        sample = upload_to_device(sample, device)  # upload tensors to device\n",
    "        optimizer.optimizer.zero_grad()  # sets gradients of weigths and bias to zero\n",
    "        pred = model(sample)  # forward call\n",
    "\n",
    "        loss = nse_basin_averaged(y_sim=pred[\"y_hat\"], y_obs=sample[\"y_obs\"], per_basin_target_std=sample[\"basin_std\"])\n",
    "\n",
    "        loss.backward()  # backpropagates\n",
    "        \n",
    "        optimizer.clip_grad_and_step(epoch, idx) # clip gradients and update weights\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        # remove from cuda\n",
    "        del sample, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # training report\n",
    "    report = f'Epoch: {epoch:<2} | Loss training: {\"%.3f \"% (np.mean(total_loss))}'\n",
    "\n",
    "    # Validation -----------------------------------------------------------------------------------------------------\n",
    "    if epoch % model_configuration[\"validate_every\"] == 0:\n",
    "        model.eval()\n",
    "        validation_results = {}\n",
    "        with torch.no_grad():\n",
    "            # If we define validate_n_random_basins as 0 or negative, we take all the basins\n",
    "            if model_configuration[\"validate_n_random_basins\"] <= 0:\n",
    "                validation_basin_ids = validation_dataset.keys()\n",
    "            else:\n",
    "                keys = list(validation_dataset.keys())\n",
    "                validation_basin_ids = random.sample(keys, model_configuration[\"validate_n_random_basins\"])\n",
    "\n",
    "            # go through each basin that will be used for validation\n",
    "            for basin in validation_basin_ids:\n",
    "                loader = DataLoader(\n",
    "                    dataset=validation_dataset[basin],\n",
    "                    batch_size=model_configuration[\"batch_size_evaluation\"],\n",
    "                    shuffle=False,\n",
    "                    drop_last=False,\n",
    "                    collate_fn=validation_dataset[basin].collate_fn,\n",
    "                )\n",
    "\n",
    "                df_ts = pd.DataFrame()\n",
    "                for sample in loader:\n",
    "                    sample = upload_to_device(sample, device)\n",
    "                    pred = model(sample)\n",
    "                    # backtransformed information\n",
    "                    y_sim = pred[\"y_hat\"] * validation_dataset[basin].scaler[\"y_std\"].to(device) + validation_dataset[\n",
    "                        basin\n",
    "                    ].scaler[\"y_mean\"].to(device)\n",
    "\n",
    "                    # join results in a dataframe and store them in a dictionary (is easier to plot later)\n",
    "                    df = pd.DataFrame(\n",
    "                        {\n",
    "                            \"y_obs\": sample[\"y_obs\"].flatten().cpu().detach(),\n",
    "                            \"y_sim\": y_sim[:, -model_configuration[\"predict_last_n_evaluation\"] :, :]\n",
    "                            .flatten()\n",
    "                            .cpu()\n",
    "                            .detach(),\n",
    "                        },\n",
    "                        index=pd.to_datetime(sample[\"date\"].flatten()),\n",
    "                    )\n",
    "\n",
    "                    df_ts = pd.concat([df_ts, df], axis=0)\n",
    "\n",
    "                    # remove from cuda\n",
    "                    del sample, pred, y_sim\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                validation_results[basin] = df_ts\n",
    "\n",
    "            # average loss validation\n",
    "            loss_validation = nse(df_results=validation_results)\n",
    "            report += f'| NSE validation: {\"%.3f \"% (loss_validation)}'\n",
    "\n",
    "    # save model after every epoch\n",
    "    path_saved_model = path_save_folder + \"/epoch_\" + str(epoch)\n",
    "    torch.save(model.state_dict(), path_saved_model)\n",
    "\n",
    "    # print epoch report\n",
    "    report += (\n",
    "        f'| Epoch time: {\"%.1f \"% (time.time()-epoch_start_time)} s | '\n",
    "        f'LR:{\"%.5f \"% (optimizer.optimizer.param_groups[0][\"lr\"])}'\n",
    "    )\n",
    "    print(report)\n",
    "    write_report(file_path=path_save_folder + \"/run_progress.txt\", text=report)\n",
    "    # modify learning rate\n",
    "    optimizer.update_optimizer_lr(epoch=epoch)\n",
    "\n",
    "# print final report\n",
    "report = f'Total training time: {\"%.1f \"% (time.time()-training_time)} s'\n",
    "print(report)\n",
    "write_report(file_path=path_save_folder + \"/run_progress.txt\", text=report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 6. Test LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case I already trained an LSTM I can re-construct the model\n",
    "# model = modelclass(model_configuration=model_configuration).to(device)\n",
    "# model.load_state_dict(torch.load(path_save_folder + \"/epoch_20\", map_location=device))\n",
    "\n",
    "# We can read the training scaler or read a previously stored one\n",
    "scaler = training_dataset.scaler\n",
    "# with open(path_save_folder + \"/scaler.pickle\", \"rb\") as file:\n",
    "#    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In evaluation (validation and testing) we will create an individual dataset per basin. This will give us more \n",
    "# flexibility\n",
    "entities_ids = np.loadtxt(path_entities, dtype=\"str\").tolist()\n",
    "entities_ids = [entities_ids] if isinstance(entities_ids, str) else entities_ids\n",
    "testing_dataset = {}\n",
    "for entity in entities_ids:\n",
    "    dataset = Datasetclass(\n",
    "        dynamic_input=dynamic_input,\n",
    "        forcing=forcing,\n",
    "        target=target,\n",
    "        sequence_length=model_configuration[\"seq_length\"],\n",
    "        time_period=testing_period,\n",
    "        path_data=path_data,\n",
    "        entity=entity,\n",
    "        check_NaN=False,\n",
    "        static_input=static_input,\n",
    "    )\n",
    "\n",
    "    dataset.scaler = scaler\n",
    "    dataset.standardize_data(standardize_output=False)\n",
    "    testing_dataset[entity] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_results = {}\n",
    "with torch.no_grad():\n",
    "    for basin, dataset in testing_dataset.items():\n",
    "        loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=model_configuration[\"batch_size_evaluation\"],\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            collate_fn=testing_dataset[basin].collate_fn,\n",
    "        )\n",
    "\n",
    "        df_ts = pd.DataFrame()\n",
    "        for sample in loader:\n",
    "            sample = upload_to_device(sample, device)  # upload tensors to device\n",
    "            pred = model(sample)\n",
    "            # backtransformed information\n",
    "            y_sim = pred[\"y_hat\"] * dataset.scaler[\"y_std\"].to(device) + dataset.scaler[\"y_mean\"].to(device)\n",
    "\n",
    "            # join results in a dataframe and store them in a dictionary (is easier to plot later)\n",
    "            df = pd.DataFrame(\n",
    "                {\n",
    "                    \"y_obs\": sample[\"y_obs\"].flatten().cpu().detach(),\n",
    "                    \"y_sim\": y_sim[:, -model_configuration[\"predict_last_n_evaluation\"] :, :].flatten().cpu().detach(),\n",
    "                },\n",
    "                index=pd.to_datetime(sample[\"date\"].flatten()),\n",
    "            )\n",
    "\n",
    "            df_ts = pd.concat([df_ts, df], axis=0)\n",
    "\n",
    "            # remove from cuda\n",
    "            del sample, pred, y_sim\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        test_results[basin] = df_ts\n",
    "\n",
    "# Save results as a pickle file\n",
    "with open(path_save_folder + \"/test_results.pickle\", \"wb\") as f:\n",
    "    pickle.dump(test_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 7. Initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss testing\n",
    "loss_testing = nse(df_results=test_results, average=False)\n",
    "df_NSE = pd.DataFrame(data={\"basin_id\": testing_dataset.keys(), \"NSE\": np.round(loss_testing, 3)})\n",
    "df_NSE = df_NSE.set_index(\"basin_id\")\n",
    "df_NSE.to_csv(path_save_folder + \"/NSE_testing.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "plt.hist(df_NSE[\"NSE\"], bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "# Add NSE statistics to the plot\n",
    "plt.text(\n",
    "    0.01,\n",
    "    0.8,\n",
    "    (\n",
    "        f'Mean: {\"%.2f\" % df_NSE[\"NSE\"].mean():>7}\\n'\n",
    "        f'Median: {\"%.2f\" % df_NSE[\"NSE\"].median():>0}\\n'\n",
    "        f'Max: {\"%.2f\" % df_NSE[\"NSE\"].max():>9}\\n'\n",
    "        f'Min: {\"%.2f\" % df_NSE[\"NSE\"].min():>10}'\n",
    "    ),\n",
    "    transform=plt.gca().transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "\n",
    "# Format plot\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "plt.xlabel(\"NSE\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Frequency\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"NSE Histogram\", fontsize=16, fontweight=\"bold\")\n",
    "# plt.savefig(save_folder+\"/NSE_Histogram.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulated and observed discharges\n",
    "basin_to_analyze = \"01022500\"\n",
    "\n",
    "plt.plot(test_results[basin_to_analyze][\"y_obs\"], label=\"observed\", color=color_palette[\"observed\"])\n",
    "plt.plot(test_results[basin_to_analyze][\"y_sim\"], label=\"simulated\", alpha=0.5, color=color_palette[\"simulated\"])\n",
    "\n",
    "# Format plot\n",
    "plt.xlabel(\"Date\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Discharge [mm/d]\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"Result comparison\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "42b7dc197ee81dd2f6541889b0e14556b882d218c1e7c97db94bc0f7b191f034"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
