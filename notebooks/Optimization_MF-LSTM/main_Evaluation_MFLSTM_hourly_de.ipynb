{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test MF-LSTM performance for Rainfall-runoff prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Description**\n",
    "\n",
    "(1) Loading model from model weight file, and laod test dataset from model_configuration_file (see model training file);\n",
    "\n",
    "(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from hy2dl.aux_functions.functions_evaluation import nse\n",
    "from hy2dl.aux_functions.utils import upload_to_device, create_folder\n",
    "from hy2dl.datasetzoo.hourlycamelsde import HourlyCAMELS_DE as Datasetclass\n",
    "from hy2dl.modelzoo.mflstm import MFLSTM as modelclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load model and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_configuration_file = r\"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/Alex_test/test_seed_110/model_config.json\"\n",
    "model_weight_path = r\"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/Alex_test/test_seed_110/weights/epoch_4\"\n",
    "scaler_path = r\"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/Alex_test/test_seed_110/scaler.pickle\"\n",
    "test_result_save_path = r\"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/Alex_test/test_seed_110/test_epoch4\"\n",
    "# test_result_save_path = r\"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/pred_24_stride_1/30_basins/2_day_seed_110/test_results\"\n",
    "\n",
    "# model_configuration_file = r\"D:\\Research\\Projects\\Hy2DL\\results\\14_day_in_hourly_pred_last_24_seed_110\\model_config.json\"\n",
    "# model_weight_path = r\"D:\\Research\\Projects\\Hy2DL\\results\\14_day_in_hourly_pred_last_24_seed_110\\best_model_at_epoch_30\"\n",
    "# scaler_path = r\"D:\\Research\\Projects\\Hy2DL\\results\\14_day_in_hourly_pred_last_24_seed_110\\scaler.pickle\"\n",
    "# test_result_save_path = r\"D:\\Research\\Projects\\Hy2DL\\results\\14_day_in_hourly_pred_last_24_seed_110\\test02\"\n",
    "\n",
    "if not os.path.exists(test_result_save_path):\n",
    "    os.makedirs(test_result_save_path)\n",
    "\n",
    "# device to test the model\n",
    "running_device = \"gpu\"\n",
    "\n",
    "# check if model will be run in gpu or cpu and define device\n",
    "if running_device == \"gpu\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = \"cuda:0\"\n",
    "elif running_device == \"cpu\":\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model configuration from the JSON file\n",
    "with open(model_configuration_file, \"r\") as f:\n",
    "    full_config = json.load(f)\n",
    "\n",
    "model_configuration = full_config[\"model_configuration\"]\n",
    "\n",
    "model = modelclass(model_configuration=model_configuration).to(device)\n",
    "model.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "\n",
    "# Load the scaler\n",
    "# (1) we can use training scaler\n",
    "# scaler = training_dataset.scaler\n",
    "\n",
    "# (2) we can also read a previously stored one\n",
    "with open(scaler_path, \"rb\") as file:\n",
    "  scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In evaluation (validation and testing) we will create an individual dataset per basin. This will give us more \n",
    "# flexibility\n",
    "\n",
    "path_entities = full_config[\"path_entities\"]\n",
    "entities_ids = np.loadtxt(path_entities, dtype=\"str\").tolist()\n",
    "entities_ids = [entities_ids] if isinstance(entities_ids, str) else entities_ids\n",
    "testing_dataset = {}\n",
    "for entity in entities_ids:\n",
    "    dataset = Datasetclass(\n",
    "        dynamic_input=full_config[\"dynamic_input\"],\n",
    "        static_input=full_config[\"static_input\"],\n",
    "        target=full_config[\"target\"],\n",
    "        time_period=full_config[\"validation_period\"],  # testing_period  # To do\n",
    "        # time_period=full_config[\"testing_period\"],\n",
    "        path_data=full_config[\"path_data\"],\n",
    "        entity=entity,\n",
    "        check_NaN=False,\n",
    "        predict_last_n=model_configuration[\"predict_last_n_evaluation\"],\n",
    "        sequence_length=model_configuration[\"seq_length\"],\n",
    "        custom_freq_processing=model_configuration[\"custom_freq_processing\"],\n",
    "        dynamic_embedding=model_configuration[\"dynamic_embeddings\"],\n",
    "        # unique_prediction_blocks=model_configuration[\"unique_prediction_blocks\"],\n",
    "        unique_prediction_blocks=model_configuration[\"unique_prediction_blocks_evaluation\"],  # To do\n",
    "    )\n",
    "\n",
    "    dataset.scaler = scaler\n",
    "    dataset.standardize_data(standardize_output=False)\n",
    "    testing_dataset[entity] = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_results = {}\n",
    "with torch.no_grad():\n",
    "    for basin, dataset in testing_dataset.items():\n",
    "        loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=model_configuration[\"batch_size_evaluation\"],\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            collate_fn=testing_dataset[basin].collate_fn,\n",
    "        )\n",
    "\n",
    "        df_ts = pd.DataFrame()\n",
    "        for sample in loader:\n",
    "            sample = upload_to_device(sample, device)  # upload tensors to device\n",
    "            pred = model(sample)\n",
    "            # backtransformed information\n",
    "            y_sim = pred[\"y_hat\"] * dataset.scaler[\"y_std\"].to(device) + dataset.scaler[\"y_mean\"].to(device)\n",
    "\n",
    "            # join results in a dataframe and store them in a dictionary (is easier to plot later)\n",
    "            df = pd.DataFrame(\n",
    "                {\n",
    "                    \"y_obs\": sample[\"y_obs\"].flatten().cpu().detach(),\n",
    "                    \"y_sim\": y_sim[:, -model_configuration[\"predict_last_n_evaluation\"] :, :].flatten().cpu().detach(),\n",
    "                },\n",
    "                index=pd.to_datetime(sample[\"date\"].flatten()),\n",
    "            )\n",
    "\n",
    "            df_ts = pd.concat([df_ts, df], axis=0)\n",
    "\n",
    "            # remove from cuda\n",
    "            del sample, pred, y_sim\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        test_results[basin] = df_ts\n",
    "\n",
    "# Save results as a pickle file\n",
    "with open(os.path.join(test_result_save_path, \"test_results.pickle\"), \"wb\") as f:\n",
    "    pickle.dump(test_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction results analysis\n",
    "\n",
    "We load model prediction results, get from \"test_results\" variable outputed by Step 2. But if the test_results file (.pickle) is output by training process, it is better and easiler to directly load that from the script \"Analysis_Rainfall_and_Q.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"***************  Evaluation process begin  ****************\")\n",
    "\n",
    "# Loss testing\n",
    "loss_testing = nse(df_results=test_results, average=False)\n",
    "df_NSE = pd.DataFrame(data={\"basin_id\": test_results.keys(), \"NSE\": np.round(loss_testing, 3)})\n",
    "df_NSE = df_NSE.set_index(\"basin_id\")\n",
    "\n",
    "# Save the NSE for each basin in a csv file\n",
    "df_NSE.to_csv(os.path.join(test_result_save_path, \"NSE_testing.csv\"), index=True, header=True)\n",
    "mean_nse = df_NSE[\"NSE\"].mean()\n",
    "median_nse = df_NSE[\"NSE\"].median()\n",
    "print(f\"Mean NSE across all basins: {mean_nse:.3f}\")\n",
    "print(f\"Median  NSE across all basins: {median_nse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "plt.hist(df_NSE[\"NSE\"], bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "# Add NSE statistics to the plot\n",
    "plt.text(\n",
    "    0.01,\n",
    "    0.8,\n",
    "    (\n",
    "        f'Mean: {\"%.2f\" % df_NSE[\"NSE\"].mean():>7}\\n'\n",
    "        f'Median: {\"%.2f\" % df_NSE[\"NSE\"].median():>0}\\n'\n",
    "        f'Max: {\"%.2f\" % df_NSE[\"NSE\"].max():>9}\\n'\n",
    "        f'Min: {\"%.2f\" % df_NSE[\"NSE\"].min():>10}'\n",
    "    ),\n",
    "    transform=plt.gca().transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "\n",
    "# Format plot\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "plt.xlabel(\"NSE\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Frequency\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"NSE Histogram\", fontsize=16, fontweight=\"bold\")\n",
    "plt.savefig(os.path.join(test_result_save_path, \"NSE_Histogram.png\"), bbox_inches=\"tight\", pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulated and observed discharges\n",
    "basin_to_analyze = \"DE210300\"\n",
    "\n",
    "# colorblind friendly palette\n",
    "color_palette = {\"observed\": \"#377eb8\", \"simulated\": \"#4daf4a\"}\n",
    "\n",
    "# (1) Output time window of test dataset period\n",
    "plt.plot(test_results[basin_to_analyze][\"y_obs\"], label=\"observed\", color=color_palette[\"observed\"])\n",
    "plt.plot(test_results[basin_to_analyze][\"y_sim\"], label=\"simulated\", alpha=0.5, color=color_palette[\"simulated\"])\n",
    "\n",
    "# # (2) Output custom time window\n",
    "# start_date = \"2019-01-01 01:00:00\"\n",
    "# end_date = \"2019-02-01 01:00:00\"\n",
    "# plt.plot(test_results[basin_to_analyze][\"y_obs\"][start_date:end_date], label=\"observed\", color=color_palette[\"observed\"])\n",
    "# plt.plot(test_results[basin_to_analyze][\"y_sim\"][start_date:end_date], label=\"simulated\", alpha=0.5, color=color_palette[\"simulated\"])\n",
    "\n",
    "# Format plot\n",
    "plt.xlabel(\"Date\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Discharge [mm/d]\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(f\"Result comparison (basin {basin_to_analyze})\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "plt.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.savefig(os.path.join(test_result_save_path, f\"Result comparison (basin {basin_to_analyze}).png\"), bbox_inches=\"tight\", pad_inches=0)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m111"
  },
  "kernelspec": {
   "display_name": "HY3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
