{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainfall-runoff model using MF-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **General Description**\n",
    "\n",
    "The following notebook contains the code to create, train, validate, and test a rainfall-runoff model using an LSTM network architecture. The code allows for the creation of single-basin models but is conceptualized to create regional models. The code is intended as an initial introduction to the topic, prioritizing interpretability over modularity.\n",
    "\n",
    "The logic of the code is heavily based on [Neural Hydrology](https://doi.org/10.21105/joss.04050) [1]. For a more flexible, robust, and modular implementation of deep learning methods in hydrological modeling, we advise the use of Neural Hydrology. \n",
    "\n",
    "**Experiment Details**\n",
    "- In this example we use the MF-LSTM (multi-frequency LSTM) architecture, which allow us to work the data at different frequencies (daily/hourly). \n",
    "- This experiment use a similar setup as the experiments presented in [2].\n",
    "\n",
    "**Authors:**\n",
    "- Eduardo Acuña Espinoza (eduardo.espinoza@kit.edu)\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1]: Kratzert, F., Gauch, M., Nearing, G., & Klotz, D. (2022). NeuralHydrology – A Python library for deep learning research in hydrology. Journal of Open Source Software, 7, 4050. https://doi.org/10.21105/joss.04050\n",
    "\n",
    "[2]: Gauch, M., Kratzert, F., Klotz, D., Nearing, G., Lin, J., & Hochreiter, S. (2021). Rainfall–runoff prediction at multiple timescales with a single long short-term memory network. Hydrology and Earth System Sciences, 25(4), 2045–2062. https://doi.org/10.5194/hess-25-2045-2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "# Import classes and functions from other files\n",
    "from hy2dl.aux_functions.functions_evaluation import nse\n",
    "from hy2dl.aux_functions.functions_training import nse_basin_averaged\n",
    "from hy2dl.aux_functions.utils import Optimizer, create_folder, set_random_seed, upload_to_device, write_report\n",
    "from hy2dl.datasetzoo.hourlycamelsde import HourlyCAMELS_DE as Datasetclass\n",
    "from hy2dl.modelzoo.mflstm import MFLSTM as modelclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the squeue length for each frequency of MF-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1W: n_steps:  24  freqs_factor:  168\n",
      "1D: n_steps:  193  freq_factor:  24\n",
      "1h: n_steps:  96  freq_factor:  1\n",
      "Total n_steps in a sequence:  313\n"
     ]
    }
   ],
   "source": [
    "# # (1) weekly-daily-hourly resolution\n",
    "# n_month_in_weekly = 6   # the first n month in weekly resolution \n",
    "# n_days_in_hourly = 4     # the last n days in hourly resolution, and the remaining days are in daily resolution\n",
    "\n",
    "# n_steps_in_weekly = n_month_in_weekly * 4\n",
    "# freq_factor_in_weekly = 24 * 7\n",
    "\n",
    "# n_steps_in_hourly = n_days_in_hourly * 24\n",
    "# freq_factor_in_hourly = 1\n",
    "\n",
    "# n_steps_in_daily = 365 - (n_month_in_weekly * 4 * 7) - n_days_in_hourly\n",
    "# freq_factor_in_daily = 24\n",
    "\n",
    "# print(\"1W: n_steps: \", n_steps_in_weekly, \" freqs_factor: \", freq_factor_in_weekly)\n",
    "# print(\"1D: n_steps: \", n_steps_in_daily, \" freq_factor: \", freq_factor_in_daily)\n",
    "# print(\"1h: n_steps: \", n_steps_in_hourly, \" freq_factor: \", freq_factor_in_hourly)\n",
    "# print(\"Total n_steps in a sequence: \", n_steps_in_weekly + n_steps_in_daily + n_steps_in_hourly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize information\n",
    "\n",
    "Training dataset setting:\n",
    "\n",
    "| *predict_last_n*                   | 1          | >1             | >1              |\n",
    "|----------------------------------|------------|----------------|-----------------|\n",
    "| *unique_prediction_blocks_training*| True/False | True           | False           |\n",
    "| The timestep of target discharge overlap? | No   | No             | Yes (stride=1)  |\n",
    "| Training data amount             | ——         | Less           | More            |\n",
    "\n",
    "Validation and test dataset setting:\n",
    "\n",
    "| *predict_last_n_evaluation*           | 1            | >1           |\n",
    "|-------------------------------------|--------------|--------------|\n",
    "| *unique_prediction_blocks_evaluation* | True/False   | True         |\n",
    "| The timestep of target discharge overlap? | No       | No           |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment name\n",
    "# experiment_name = \"150_day\"\n",
    "experiment_name = \"test\"\n",
    "\n",
    "# paths to access the information\n",
    "# My PC\n",
    "# path_entities = r\"D:\\Research\\Projects\\Hy2DL\\data\\basin_id\\basin_ids_workshop_part1.txt\"\n",
    "# path_data = r\"D:\\Research\\Projects\\Hy2DL\\data\\CAMELS_DE\"\n",
    "\n",
    "## BwCluster3.0\n",
    "# path_entities = \"/pfs/data6/home/ka/ka_iwu/ka_qa8171/Project/Hy2DL/data/basin_id/basins_camels_de_hourly_292_Bayern.txt\"\n",
    "# path_data = \"/pfs/data6/home/ka/ka_iwu/ka_qa8171/Project/Hy2DL/data/CAMELS_DE/\"\n",
    "\n",
    "## Haicore@KIT\n",
    "# path_entities = \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/data/basin_id/basins_camels_de_hourly_292_Bayern.txt\"\n",
    "path_entities = \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/data/basin_id/basin_ids_workshop_part1.txt\"\n",
    "path_data = \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/data/CAMELS_DE/\"\n",
    "\n",
    "# dynamic forcings and target\n",
    "dynamic_input = {\n",
    "    \"1W\": [\n",
    "       \"precipitation_resampled\",\n",
    "       \"air_temperature_mean_mean\",\n",
    "       \"global_shortwave_radiation_mean\",\n",
    "    #    \"air_pressure_surface_mean\",\n",
    "       \"relative_humidity_mean\",\n",
    "       \"wind_speed_mean\",\n",
    "    ],\n",
    "    \"1D\": [\n",
    "        \"precipitation_resampled\",\n",
    "        \"air_temperature_mean_mean\",\n",
    "        \"global_shortwave_radiation_mean\",\n",
    "        # \"air_pressure_surface_mean\",  \n",
    "        \"relative_humidity_mean\",\n",
    "        \"wind_speed_mean\",\n",
    "        #\"discharge_spec_obs\",\n",
    "    ],\n",
    "    \"1h\": [\n",
    "        \"precipitation_sum_mean\",\n",
    "        \"air_temperature_mean_mean\",\n",
    "        \"global_shortwave_radiation_mean\",\n",
    "        # \"air_pressure_surface_mean\",  \n",
    "        \"relative_humidity_mean\",\n",
    "        \"wind_speed_mean\",\n",
    "        #\"discharge_spec_obs\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "target = [\"discharge_spec_obs\"]\n",
    "\n",
    "# static attributes that will be used. If one is not using static_inputs, initialize the variable as an empty list.\n",
    "static_input = [\n",
    "    \"area\",\n",
    "    \"elev_mean\",\n",
    "    \"clay_0_30cm_mean\",\n",
    "    \"sand_0_30cm_mean\",\n",
    "    \"silt_0_30cm_mean\",\n",
    "    \"artificial_surfaces_perc\",\n",
    "    \"agricultural_areas_perc\",\n",
    "    \"forests_and_seminatural_areas_perc\",\n",
    "    \"wetlands_perc\",\n",
    "    \"water_bodies_perc\",\n",
    "    \"p_mean\",\n",
    "    \"p_seasonality\",\n",
    "    \"frac_snow\",\n",
    "    \"high_prec_freq\",\n",
    "    \"low_prec_freq\",\n",
    "    \"high_prec_dur\",\n",
    "    \"low_prec_dur\",\n",
    "]\n",
    "\n",
    "# # # time periods (15:3:5)\n",
    "# training_period = [\"2001-01-01 01:00:00\", \"2015-12-31 23:00:00\"]\n",
    "# validation_period = [\"2016-01-01 01:00:00\", \"2018-12-31 23:00:00\"]\n",
    "# testing_period = [\"2019-01-01 01:00:00\", \"2023-12-31 23:00:00\"]\n",
    "\n",
    "# # time periods (for short test)\n",
    "training_period = [\"2001-01-01 01:00:00\", \"2003-01-02 23:00:00\"]\n",
    "validation_period = [\"2016-01-01 01:00:00\", \"2017-01-02 23:00:00\"] \n",
    "testing_period = [\"2019-01-01 01:00:00\", \"2020-01-01 23:00:00\"]\n",
    "\n",
    "# model configuration\n",
    "model_configuration = {\n",
    "    \"n_dynamic_channels_lstm\": 5,  # 5 is my case\n",
    "    \"no_of_layers\": 1,\n",
    "    \"seq_length\": 365 * 24,  # 1 year of hourly data\n",
    "    \"custom_freq_processing\": {\n",
    "        \"1W\": {\n",
    "           \"n_steps\": 24,  # 24 weeks (6 months)\n",
    "           \"freq_factor\": 168,  # 24*7 hours in a week\n",
    "        },\n",
    "        \"1D\": {\n",
    "           \"n_steps\": 193,  # ~2 months (197 - 1 days)\n",
    "           \"freq_factor\": 24,  # 24 hours in a day\n",
    "        },\n",
    "        \"1h\": {\n",
    "           \"n_steps\": 96,  # 1 days of hourly data\n",
    "           \"freq_factor\": 1\n",
    "        }\n",
    "    },\n",
    "    \"predict_last_n\": 24,      # \"predict_last_n\" for training       \n",
    "    \"unique_prediction_blocks_training\": True,\n",
    "    \"predict_last_n_evaluation\": 24,\n",
    "    \"unique_prediction_blocks_evaluation\": True,\n",
    "    \"dynamic_embeddings\": True,   # originally True\n",
    "    \"hidden_size\": 128,\n",
    "    \"batch_size_training\": 256,  # 256\n",
    "    \"batch_size_evaluation\": 1024, # 1024\n",
    "    \"dropout_rate\": 0.4,\n",
    "    \"no_of_epochs\": 30, # 30\n",
    "    \"learning_rate\": {1: 5e-4, 10: 1e-4, 25: 1e-5}, # {1: 5e-4, 10: 1e-4, 25: 1e-5} for 30 epochs\n",
    "    \"set_forget_gate\": 3,\n",
    "    \"validate_every\": 1, # 5\n",
    "    \"validate_n_random_basins\": -1,\n",
    "}\n",
    "\n",
    "# device to train the model\n",
    "running_device = \"gpu\"  # cpu or gpu\n",
    "\n",
    "# define random seed\n",
    "seed = 110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate additional information necessary for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder './results/test_seed_110' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create folder to store the results\n",
    "path_save_folder = \"./results/\" + experiment_name + \"_seed_\" + str(seed)\n",
    "create_folder(folder_path=path_save_folder)\n",
    "\n",
    "weights_save_path = os.path.join(path_save_folder, \"weights\")\n",
    "if not os.path.exists(weights_save_path):\n",
    "    os.makedirs(weights_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A100-SXM4-40GB MIG 1g.5gb\n"
     ]
    }
   ],
   "source": [
    "# check if model will be run in gpu or cpu and define device\n",
    "if running_device == \"gpu\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = \"cuda:0\"\n",
    "elif running_device == \"cpu\":\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include information about input size for each frequency\n",
    "if isinstance(dynamic_input, list):\n",
    "    model_configuration[\"dynamic_input_size\"] = len(dynamic_input)\n",
    "elif isinstance(dynamic_input, dict):\n",
    "    model_configuration[\"dynamic_input_size\"] = {key: len(value) for key, value in dynamic_input.items()}\n",
    "\n",
    "# include information about input size for lstm\n",
    "model_configuration[\"input_size_lstm\"] = model_configuration[\"n_dynamic_channels_lstm\"] + len(static_input)\n",
    "# if I am processing multiple frequencies and do not have custom dynamic embeddings for each frequency, I add an\n",
    "# additional channel that will be used as a flag to indicate the frequency.\n",
    "if model_configuration.get(\"custom_freq_processing\") and not model_configuration.get(\"dynamic_embeddings\"):\n",
    "    model_configuration[\"input_size_lstm\"] = model_configuration[\"input_size_lstm\"] + 1\n",
    "\n",
    "# If predict_last_n was not defined, we initialize it as 1\n",
    "if not model_configuration.get(\"predict_last_n\"):\n",
    "    model_configuration[\"predict_last_n\"] = 1\n",
    "if not model_configuration.get(\"predict_last_n_evaluation\"):\n",
    "    model_configuration[\"predict_last_n_evaluation\"] = 1\n",
    "\n",
    "# Check connection between predict_last_n_evaluation and unique_prediction_blocks_evaluation. If predict_last_n_evaluation is larger than 1, and\n",
    "# unique_prediction_blocks is False, we change for evaluation purposes predict_last_n_evaluation to 1. This avoid having\n",
    "# multiple predictions for the same time step due to the overlap of the sequences.\n",
    "if model_configuration.get(\"predict_last_n_evaluation\", 1) > 1 and not model_configuration.get(\"unique_prediction_blocks_evaluation\"):\n",
    "    print(\n",
    "        (\n",
    "            \"Warning: predict_last_n_evaluation > 1 and unique_prediction_blocks_evaluation = False.\"\n",
    "            + \" This creates overlapping sequences during evaluation. To avoid this, predict_last_n_evaluation will be changed to\"\n",
    "            + \" 1 during evaluation (validation / testing). This will not affect the training process.\"\n",
    "        )\n",
    "    )\n",
    "    model_configuration[\"predict_last_n_evaluation\"] = 1\n",
    "else:\n",
    "    model_configuration[\"predict_last_n_evaluation\"] = model_configuration.get(\"predict_last_n_evaluation\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model config\n",
    "model_config = {\n",
    "    \"name\": experiment_name,\n",
    "    \"path_entities\": path_entities,\n",
    "    \"dynamic_input\": dynamic_input,\n",
    "    \"static_input\": static_input,\n",
    "    \"target\": target,\n",
    "    \"training_period\": training_period,\n",
    "    \"validation_period\": validation_period,\n",
    "    \"testing_period\": testing_period,\n",
    "    \"path_data\": path_data,\n",
    "    \"random_seed\": seed,\n",
    "    \"model_configuration\": model_configuration\n",
    "}\n",
    "\n",
    "# write to json\n",
    "with open(path_save_folder + \"/model_config.json\", \"w\") as f:\n",
    "    json.dump(model_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Class to create the dataset object used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sequences: 718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm_tmpdir/job_1540060/ipykernel_2316941/1010754489.py:20: UserWarning: The standard deviation of the following attribute(s) is NaN or zero: ['wetlands_perc', 'water_bodies_perc', 'high_prec_dur']. The std of this attribute(s) has been forced to 1 to avoid NaN issues during normalization.\n",
      "  training_dataset.calculate_global_statistics(path_save_scaler=path_save_folder)\n"
     ]
    }
   ],
   "source": [
    "# Dataset training\n",
    "training_dataset = Datasetclass(\n",
    "    dynamic_input=dynamic_input,\n",
    "    target=target,\n",
    "    sequence_length=model_configuration[\"seq_length\"],\n",
    "    time_period=training_period,\n",
    "    path_data=path_data,\n",
    "    path_entities=path_entities,\n",
    "    check_NaN=True,\n",
    "    predict_last_n=model_configuration[\"predict_last_n\"],\n",
    "    static_input=static_input,\n",
    "    custom_freq_processing=model_configuration[\"custom_freq_processing\"],\n",
    "    dynamic_embedding=model_configuration[\"dynamic_embeddings\"],\n",
    "    unique_prediction_blocks=model_configuration[\"unique_prediction_blocks_training\"],\n",
    ")\n",
    "\n",
    "# the training data is already aggregated to the required resolution/frequency\n",
    "# Next, these data will be standardized, as follows:\n",
    "training_dataset.calculate_basin_std()\n",
    "training_dataset.calculate_global_statistics(path_save_scaler=path_save_folder)\n",
    "training_dataset.standardize_data()\n",
    "print(f\"Number of training sequences: {len(training_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sample in training dataset look like: {'x_d_1W': tensor([[  0.3173, -15.8198,  -5.6570,   7.3039,  -2.0548],\n",
      "        [ -0.5377, -11.2517,  -5.8019,   7.4122,   2.3556],\n",
      "        [  1.3836, -10.5081,  -5.1933,   5.9701,  10.8367],\n",
      "        [ -0.9546,  -4.6724,  -3.7034,  -1.0554,   5.8305],\n",
      "        [ -2.5448, -10.4575,  -2.5022,  -1.4510,  -1.2851],\n",
      "        [ -1.7913, -16.0196,  -3.1409,  -0.6882,   4.1843],\n",
      "        [ -1.1518, -14.2239,  -2.7632,   1.7817,   1.8022],\n",
      "        [  0.9836,  -2.8610,  -4.1923,   7.7953,   8.6401],\n",
      "        [  1.1329,  -5.7068,  -2.2671,   2.3902,   6.2834],\n",
      "        [  3.5865,  -5.9146,  -1.7489,   5.8885,   4.6265],\n",
      "        [ -1.0109,  -0.4078,   2.3419,  -6.9837,   2.0389],\n",
      "        [ -0.6222,  -2.9084,  -0.6032,  -0.3319,   7.2377],\n",
      "        [ -1.0828,  -9.3177,   1.2607,  -3.2005,   1.1953],\n",
      "        [ -1.3222,  -8.0261,   4.3813,  -5.5087,  -3.6855],\n",
      "        [ -0.0559,   2.9420,   2.4245,   0.2885,   3.7487],\n",
      "        [ -2.4011,   3.7151,   3.4338,  -1.4517,   4.2034],\n",
      "        [ -2.1575,  13.1518,  11.2543, -16.3749,  -1.2882],\n",
      "        [ -1.9476,   5.6760,   7.7604,  -7.6090,   2.4940],\n",
      "        [ -2.9082,  17.0582,  11.2249, -19.4394,  -1.4586],\n",
      "        [ -1.7589,   6.1335,   6.0411, -12.5123,   1.5721],\n",
      "        [  0.0779,   5.6605,   5.9343,  -6.7817,  -3.4626],\n",
      "        [ -0.0419,   9.2270,   6.7915,  -3.7343,  -4.1446],\n",
      "        [ -2.9082,  14.6053,  11.7487, -17.6073,  -5.5203],\n",
      "        [  1.1850,  16.7078,  10.0543,  -7.2375,  -4.9713]]), 'x_d_1D': tensor([[-1.0992e+00,  7.2925e+00,  5.2266e+00, -8.7077e+00,  4.7975e+00],\n",
      "        [-1.0992e+00,  9.2654e+00,  5.5863e+00, -9.4055e+00,  1.9864e+00],\n",
      "        [ 3.4249e+00,  9.2776e+00,  4.5531e+00, -8.0268e+00,  2.0660e-01],\n",
      "        [-8.1598e-01,  5.9662e+00,  1.5306e+00, -4.3390e-01,  3.6074e+00],\n",
      "        [-1.0992e+00,  4.9712e+00,  3.2806e-01,  5.1677e-01,  3.5603e+00],\n",
      "        [-1.0992e+00,  5.1536e+00,  1.1803e+00, -4.3207e+00, -6.5625e-01],\n",
      "        [-8.0853e-01,  7.0642e+00,  3.2340e+00, -6.7171e+00,  1.4238e+00],\n",
      "        [-5.3276e-01,  3.9574e+00,  2.8263e+00, -3.0777e+00,  4.3372e+00],\n",
      "        [-7.7871e-01,  3.6916e+00,  2.6434e+00, -2.7640e+00,  1.3378e+00],\n",
      "        [ 5.3739e+00,  3.4943e+00,  2.1687e+00,  8.4554e-01, -7.7867e-01],\n",
      "        [ 4.0175e+00,  5.0486e+00,  1.2764e+00,  2.4524e+00,  2.2207e+00],\n",
      "        [-1.0992e+00,  3.5322e+00,  1.2506e+00, -1.1125e+00, -5.0894e+00],\n",
      "        [ 1.3157e+00,  3.1912e+00,  2.7843e-01,  7.8251e-01, -4.2819e+00],\n",
      "        [-6.9300e-01,  4.5004e+00,  2.9958e+00, -2.2793e+00,  9.9477e-02],\n",
      "        [ 3.8399e-01,  4.2158e+00,  3.2842e+00, -6.9860e-01,  5.2907e+00],\n",
      "        [-5.0667e-01,  3.4702e+00,  1.1430e+00,  1.4897e+00,  4.1453e+00],\n",
      "        [-4.3214e-01,  2.6047e+00, -6.5755e-01,  2.9036e+00,  1.6851e+00],\n",
      "        [-1.0992e+00,  4.8983e+00,  3.2830e+00, -2.2658e+00, -2.8457e+00],\n",
      "        [-1.0992e+00,  7.7427e+00,  3.7367e+00, -5.7531e+00, -5.0270e+00],\n",
      "        [ 7.7156e-01,  7.8150e+00,  2.8994e+00, -2.9051e+00, -1.9852e+00],\n",
      "        [-1.0992e+00,  7.7592e+00,  3.0704e+00, -8.4182e-01, -1.9488e+00],\n",
      "        [-1.0992e+00,  8.9571e+00,  3.9918e+00, -4.5680e+00, -2.2689e+00],\n",
      "        [-1.0992e+00,  9.2474e+00,  3.2139e+00, -6.0770e+00, -3.4331e+00],\n",
      "        [-1.0992e+00,  1.0367e+01,  5.0993e+00, -1.0342e+01, -3.7451e+00],\n",
      "        [-1.0992e+00,  9.7973e+00,  4.1501e+00, -8.0118e+00, -3.4037e+00],\n",
      "        [-1.0992e+00,  8.1261e+00,  3.8117e+00, -5.2285e+00, -4.3666e+00],\n",
      "        [-1.0992e+00,  9.0209e+00,  4.4507e+00, -8.2588e+00, -4.8798e+00],\n",
      "        [-1.0992e+00,  9.6445e+00,  2.3861e+00, -5.1014e+00, -3.6196e-01],\n",
      "        [-1.0992e+00,  6.8843e+00,  5.1126e+00, -5.7485e+00, -3.1471e+00],\n",
      "        [-7.0418e-01,  8.9273e+00,  3.2041e+00, -5.8844e+00,  5.2913e-01],\n",
      "        [ 1.1815e+00,  7.1983e+00,  4.9214e-01, -3.0090e-01,  6.6922e-01],\n",
      "        [ 4.6598e-01,  4.9279e+00,  6.2724e-01, -8.6960e-01, -3.9610e-01],\n",
      "        [-1.0619e+00,  4.3502e+00,  1.6337e+00, -1.7496e+00,  3.1012e+00],\n",
      "        [ 1.6399e+00,  4.9060e+00,  1.3908e-01,  2.9763e+00,  2.0735e+00],\n",
      "        [-7.1536e-01,  5.1135e+00,  8.9963e-01,  2.0415e+00,  3.1895e+00],\n",
      "        [ 2.3493e-01,  4.9319e+00,  1.5758e+00, -2.8033e-01,  5.0482e+00],\n",
      "        [-9.5014e-01,  4.5078e+00,  2.0324e+00, -9.0026e-01,  1.6863e+00],\n",
      "        [ 6.3368e-01,  2.4063e+00,  7.3073e-01,  4.2452e-01, -6.7626e-01],\n",
      "        [-1.0992e+00,  3.1935e+00,  3.1087e+00, -2.5665e+00, -2.9788e+00],\n",
      "        [-1.0992e+00,  5.3244e+00,  2.3897e+00, -5.1710e+00, -1.9605e+00],\n",
      "        [-1.0992e+00,  7.6659e+00, -1.4407e-01, -5.7797e+00,  3.9612e-01],\n",
      "        [-1.0992e+00,  9.7569e+00,  3.1118e+00, -6.5413e+00, -4.1147e+00],\n",
      "        [-1.0992e+00,  1.1099e+01,  4.2733e+00, -9.3127e+00, -2.2901e+00],\n",
      "        [-4.3959e-01,  7.3645e+00,  9.7172e-01, -2.0458e+00, -2.2659e-01],\n",
      "        [-1.0992e+00,  6.3638e+00,  1.7035e+00, -1.6712e+00, -3.2271e+00],\n",
      "        [-1.0992e+00,  8.2004e+00,  2.1734e+00, -2.3959e+00, -5.3500e-01],\n",
      "        [ 4.7343e-01,  6.6578e+00,  1.4465e+00, -2.3529e+00,  9.2112e-01],\n",
      "        [-6.2965e-01,  6.6151e+00,  1.5260e+00, -2.9818e+00, -5.3236e+00],\n",
      "        [-1.0992e+00,  7.4427e+00,  3.3869e+00, -4.8223e+00, -3.3390e+00],\n",
      "        [-1.0992e+00,  8.0245e+00,  3.8660e+00, -5.5360e+00, -2.1088e+00],\n",
      "        [-1.0992e+00,  8.4884e+00,  2.3673e+00, -4.2332e+00, -3.2754e+00],\n",
      "        [-1.0992e+00,  9.8175e+00,  2.5325e+00, -6.0942e+00, -5.5720e+00],\n",
      "        [-1.0992e+00,  1.0519e+01,  2.8640e+00, -8.3441e+00, -5.3048e+00],\n",
      "        [-1.0992e+00,  1.0922e+01,  3.2434e+00, -1.0118e+01, -4.6468e+00],\n",
      "        [-1.0992e+00,  6.3003e+00, -1.6252e-01, -4.6260e+00, -4.9263e-01],\n",
      "        [-1.0992e+00,  3.9862e+00,  1.2407e+00, -6.1640e+00, -2.9646e+00],\n",
      "        [-1.0992e+00,  4.7492e+00,  3.3139e+00, -8.2742e+00, -4.1023e-01],\n",
      "        [ 2.1630e-01,  4.1393e+00,  4.0236e-01, -3.5618e+00, -2.2407e+00],\n",
      "        [ 4.5853e-01,  2.9618e+00, -7.6532e-01,  3.1595e+00, -3.3095e+00],\n",
      "        [-9.1660e-01,  2.8614e+00, -5.5135e-02,  1.3533e+00, -2.4561e+00],\n",
      "        [-1.0992e+00,  3.3765e+00,  2.1698e+00, -1.5942e+00,  1.0419e-01],\n",
      "        [ 1.8187e+00,  4.2599e+00, -8.0563e-01,  1.6087e+00,  2.8900e-01],\n",
      "        [ 1.2970e+00,  1.9612e+00, -7.9360e-01,  3.4597e+00,  3.8317e-01],\n",
      "        [-3.7251e-01,  1.4594e+00, -1.0727e-01,  1.5907e+00,  1.4320e+00],\n",
      "        [ 2.4611e-01,  1.4235e+00, -2.9808e-01,  3.4884e+00,  3.0077e-01],\n",
      "        [-4.5450e-01,  2.1086e+00, -1.2715e+00,  3.0923e+00,  2.2054e+00],\n",
      "        [-8.7933e-01,  2.4803e+00,  4.6454e-02, -5.5000e-01,  8.8669e+00],\n",
      "        [-2.0481e-01, -1.0909e-01, -4.1115e-01,  4.5086e-01,  7.1494e+00],\n",
      "        [-2.5326e-01,  4.3508e-01, -5.0749e-01,  2.2816e+00,  6.0758e+00],\n",
      "        [-6.5946e-01,  9.2262e-01, -9.3867e-01,  1.8249e-01,  2.9764e+00],\n",
      "        [-1.0806e+00,  2.3223e+00, -1.2693e+00,  2.4382e+00,  2.6951e+00],\n",
      "        [ 4.4572e+00,  2.0075e+00, -1.5099e+00,  2.4815e+00,  4.7833e+00],\n",
      "        [-9.1660e-01,  1.1998e+00, -2.1819e-01,  1.0032e+00, -4.4436e-01],\n",
      "        [ 1.1517e+00,  7.2909e-01, -9.0793e-01,  2.9670e+00,  1.7698e+00],\n",
      "        [ 6.7528e+00, -1.0482e-01,  1.1471e-01,  2.6998e+00,  4.7852e-01],\n",
      "        [-7.8989e-01, -5.6720e-02, -5.9288e-02,  5.6132e-01, -2.4349e+00],\n",
      "        [-1.0992e+00, -1.0340e-01, -6.5426e-01,  1.4547e+00, -1.8334e+00],\n",
      "        [ 5.9888e+00,  4.5842e-01, -1.0548e+00,  2.8192e+00,  4.9964e+00],\n",
      "        [-5.4766e-01,  1.7486e+00, -1.2876e+00,  2.6012e+00,  5.2648e+00],\n",
      "        [-7.3027e-01,  8.0280e-01, -9.8048e-01,  2.4636e+00,  1.2154e+00],\n",
      "        [-1.0992e+00,  3.2153e-01, -5.2484e-02,  4.3081e-01, -4.6703e+00],\n",
      "        [-1.0992e+00,  4.2541e-01,  1.1264e+00, -7.3411e-01, -3.6438e+00],\n",
      "        [-1.0992e+00,  7.3933e-01, -6.2249e-01,  1.8419e+00, -5.4013e+00],\n",
      "        [-1.0992e+00,  2.2988e-01, -1.2421e+00,  3.1408e+00, -4.5279e+00],\n",
      "        [-7.2281e-01,  1.4568e+00,  2.3070e-02,  1.0928e+00, -2.6421e+00],\n",
      "        [-1.0955e+00,  3.0265e+00, -1.4768e+00,  1.4841e+00,  1.0647e+00],\n",
      "        [-1.0992e+00,  2.7652e+00,  5.3672e-01, -2.4075e-01, -3.4461e+00],\n",
      "        [-4.4332e-01,  2.8941e+00, -2.2327e-01,  1.2510e+00, -2.3248e-01],\n",
      "        [-9.3151e-01,  4.0280e+00,  7.1217e-01,  1.0256e-01,  1.0654e-01],\n",
      "        [ 5.5915e-01,  4.9325e+00, -2.2197e+00,  2.5721e+00,  8.5396e+00],\n",
      "        [-1.0992e+00,  7.1843e+00, -3.2221e-01, -1.0983e+00,  6.4478e+00],\n",
      "        [ 5.5752e+00,  4.3798e+00, -1.7322e+00,  3.0020e+00, -4.8556e-01],\n",
      "        [-4.8058e-01,  2.0924e+00, -4.2783e-01,  1.6726e+00, -5.3383e-01],\n",
      "        [-1.0992e+00,  1.9165e+00, -2.2313e-01,  1.5990e+00, -2.1689e+00],\n",
      "        [ 1.0958e+00,  4.6345e+00, -4.2803e-01,  4.2059e-01,  7.5397e-01],\n",
      "        [-1.0992e+00,  3.8245e+00, -1.4740e+00,  1.8454e+00,  1.8970e+00],\n",
      "        [ 1.1940e-01,  1.8983e+00, -2.0513e+00,  8.9769e-01,  5.0152e+00],\n",
      "        [-1.0992e+00,  2.3360e+00, -6.2516e-01,  1.3178e-01,  3.2825e+00],\n",
      "        [-1.0992e+00,  2.2221e+00,  8.0215e-02,  9.9388e-01, -9.2817e-01],\n",
      "        [-1.0992e+00,  2.4945e+00, -1.2693e+00,  9.5234e-01, -1.1283e+00],\n",
      "        [-1.0992e+00,  3.2820e+00,  6.1009e-01,  4.1718e-01, -4.9658e+00],\n",
      "        [-1.0992e+00,  4.6180e+00,  5.4174e-01, -5.8145e-01, -4.7621e+00],\n",
      "        [-1.0172e+00,  4.4543e+00, -3.7584e-01,  2.1176e+00, -3.4696e+00],\n",
      "        [-1.0023e+00,  4.0345e+00, -2.1539e-01,  1.6855e+00, -2.2678e+00],\n",
      "        [-1.0992e+00,  3.4906e+00,  7.9044e-03,  2.5548e-01, -3.7357e+00],\n",
      "        [-1.0992e+00,  1.7141e+00, -1.9833e+00,  4.1812e+00,  1.2448e+00],\n",
      "        [-1.0321e+00,  1.9802e+00, -1.0468e+00,  3.5778e+00,  1.1848e+00],\n",
      "        [-1.0768e+00,  2.7009e+00, -5.3195e-01,  2.4741e+00,  5.0447e+00],\n",
      "        [-1.0992e+00,  1.9572e+00, -6.8904e-01,  9.4264e-01,  1.9394e+00],\n",
      "        [-3.7624e-01,  1.7329e+00, -2.0709e+00,  1.3761e+00,  1.2272e+00],\n",
      "        [-1.0992e+00,  2.1029e+00, -1.1057e+00,  2.8237e+00, -1.3360e-01],\n",
      "        [ 1.7927e+00,  8.9985e-01, -1.9900e+00,  4.1355e+00, -2.5644e+00],\n",
      "        [-6.5574e-01,  1.6694e+00, -1.7879e+00,  3.2879e+00,  3.7728e-01],\n",
      "        [-9.4269e-01,  1.6535e+00, -1.7025e+00,  2.7295e+00, -5.5384e-01],\n",
      "        [-1.0992e+00,  1.5969e+00, -6.9933e-01,  1.9841e+00, -6.4095e-01],\n",
      "        [-4.6940e-01,  1.4130e+00, -2.1456e+00,  2.8366e+00, -9.3575e-02],\n",
      "        [-1.0992e+00,  1.5886e+00, -1.9548e+00,  4.4277e+00, -5.4472e+00],\n",
      "        [-1.0992e+00,  1.2087e+00, -2.4658e+00,  3.2190e+00,  9.5173e-01],\n",
      "        [-1.0992e+00,  3.3549e+00, -8.4248e-01, -2.2988e+00,  3.7216e+00],\n",
      "        [ 1.0697e+00,  1.1059e+00, -2.1487e+00, -5.6101e-01,  5.8157e+00],\n",
      "        [-9.6132e-01, -1.8708e+00, -7.6202e-01, -3.0680e-01, -1.8793e+00],\n",
      "        [-1.0992e+00, -1.8609e+00, -1.2927e+00,  1.0788e+00, -5.2295e+00],\n",
      "        [-1.0992e+00, -1.4994e+00, -1.5652e+00,  6.8515e-01, -3.9581e+00],\n",
      "        [-1.0992e+00, -1.7809e+00, -9.6319e-01,  2.3244e+00, -5.2130e+00],\n",
      "        [-1.0992e+00, -2.2064e+00, -1.8472e+00,  1.4423e-01, -3.7498e+00],\n",
      "        [ 4.5480e-01, -2.1682e+00, -2.5010e+00,  3.3688e+00,  4.7751e+00],\n",
      "        [ 1.4176e-01, -2.1155e-01, -2.5252e+00,  3.5049e+00,  5.6238e+00],\n",
      "        [ 9.7751e+00, -2.4079e+00, -2.4923e+00,  2.2736e+00,  1.0282e+01],\n",
      "        [-1.0135e+00, -5.7708e+00, -1.8999e+00,  6.3903e-01, -1.6215e+00],\n",
      "        [-1.0992e+00, -7.1036e+00, -6.5765e-01,  6.7052e-02, -3.0906e+00],\n",
      "        [-1.0992e+00, -5.1729e+00, -1.2439e+00, -3.2167e+00, -5.2177e+00],\n",
      "        [-3.6133e-01, -2.3991e+00, -2.1374e+00,  3.3815e+00, -4.8092e+00],\n",
      "        [-9.2405e-01, -3.3741e+00, -1.1844e+00,  8.6716e-01,  4.6505e-02],\n",
      "        [-9.6505e-01, -5.2158e+00, -2.3761e+00,  2.1682e+00, -1.3260e+00],\n",
      "        [-1.0992e+00, -6.2165e+00, -8.4968e-01,  1.0335e-01, -1.1989e+00],\n",
      "        [-1.0992e+00, -4.4104e+00, -2.0615e+00,  3.1342e+00, -3.0941e+00],\n",
      "        [-1.0992e+00, -3.8793e+00, -1.0241e+00,  1.2290e+00,  1.6180e+00],\n",
      "        [-1.0992e+00, -5.8428e+00, -2.2150e+00,  3.0639e+00,  1.2849e+00],\n",
      "        [-1.0992e+00, -4.3759e+00, -2.5413e+00,  3.4951e+00, -3.4155e+00],\n",
      "        [-1.0992e+00, -2.9967e+00, -2.7324e+00,  3.7784e+00, -5.7992e+00],\n",
      "        [-1.0992e+00, -3.0329e+00, -2.4098e+00,  3.6831e-01, -7.4741e-02],\n",
      "        [ 2.7243e+00, -4.0307e+00, -2.7252e+00,  2.3667e+00,  9.2271e+00],\n",
      "        [-1.0284e+00, -5.4515e+00, -1.9601e+00,  2.4864e+00,  4.6439e-01],\n",
      "        [ 1.0077e-01, -4.9048e+00, -2.5791e+00,  4.2393e+00,  1.4603e+00],\n",
      "        [-5.1412e-01, -2.2408e+00, -2.4114e+00,  4.7436e+00, -1.4732e+00],\n",
      "        [ 3.6634e+00, -1.9431e+00, -2.6768e+00,  4.5459e+00, -6.4213e-01],\n",
      "        [-9.4269e-01, -3.6619e+00, -2.6240e+00,  3.5771e+00,  2.4897e-01],\n",
      "        [ 7.2684e-01, -3.3818e+00, -2.2161e+00,  3.0159e+00,  1.4191e+00],\n",
      "        [ 2.3367e+00, -2.7198e+00, -2.6716e+00,  4.0182e+00,  4.9646e+00],\n",
      "        [ 1.5392e+00,  1.1775e-01, -2.6036e+00,  4.7519e+00, -1.4850e+00],\n",
      "        [ 3.5418e-01,  8.6826e-01, -2.5744e+00,  4.5408e+00,  1.9365e-01],\n",
      "        [-8.4952e-01, -2.0955e-01, -2.6853e+00,  4.6798e+00, -3.7604e+00],\n",
      "        [-1.0918e+00, -1.6118e+00, -2.7178e+00,  4.5661e+00, -9.2935e-01],\n",
      "        [ 9.2063e-01, -1.3591e+00, -2.7911e+00,  3.8391e+00,  3.0859e+00],\n",
      "        [-8.9424e-01, -1.4433e+00, -2.3324e+00,  2.5797e+00,  5.5214e+00],\n",
      "        [-7.9735e-01, -2.4113e+00, -2.7045e+00,  7.4923e-01,  4.3902e+00],\n",
      "        [-1.0992e+00, -4.8786e+00, -1.5270e+00,  1.3354e+00, -1.0200e+00],\n",
      "        [-1.0992e+00, -5.6035e+00, -1.7634e+00,  4.0041e-01,  2.7504e+00],\n",
      "        [-1.0992e+00, -6.8150e+00, -1.9232e+00, -7.9255e-01,  2.3761e+00],\n",
      "        [-1.0992e+00, -6.2783e+00, -2.4459e+00, -5.4499e+00, -2.4408e+00],\n",
      "        [-1.0992e+00, -5.7759e+00, -2.4758e+00,  6.5410e-01, -1.5544e+00],\n",
      "        [-1.0992e+00, -5.0747e+00, -2.6587e+00,  3.9311e+00, -1.0435e+00],\n",
      "        [-1.0992e+00, -7.2181e+00, -2.3057e+00, -3.1765e+00,  5.7627e+00],\n",
      "        [-1.0992e+00, -1.1116e+01, -1.6271e+00, -3.5544e+00,  6.1653e+00],\n",
      "        [-1.0992e+00, -8.8711e+00, -2.1278e+00, -3.2317e+00,  1.7251e+00],\n",
      "        [-1.0992e+00, -7.6729e+00, -2.2551e+00, -2.7063e+00,  1.8228e+00],\n",
      "        [-1.0992e+00, -8.1279e+00, -2.7346e+00,  3.6077e+00, -4.3384e+00],\n",
      "        [-1.0992e+00, -6.7462e+00, -2.4021e+00,  3.3824e+00, -4.2089e+00],\n",
      "        [-1.0992e+00, -5.7273e+00, -2.6662e+00,  3.6807e+00,  2.8900e-01],\n",
      "        [-8.2343e-01, -7.5001e+00, -1.9709e+00, -8.8061e-01, -1.1106e+00],\n",
      "        [-1.6755e-01, -7.2115e+00, -2.6436e+00,  1.1980e+00,  1.2563e+01],\n",
      "        [-5.4394e-01, -6.5415e+00, -2.6720e+00,  3.2591e+00,  4.1865e+00],\n",
      "        [-4.3959e-01, -1.0430e+01, -2.0647e+00,  2.1866e-01, -1.7898e+00],\n",
      "        [-8.1971e-01, -9.2991e+00, -2.6585e+00,  2.3072e-01,  9.4507e+00],\n",
      "        [ 8.6846e-01, -5.2491e+00, -2.7614e+00,  3.5783e+00,  1.2464e+01],\n",
      "        [-6.7064e-01, -6.7974e+00, -2.6648e+00,  2.3280e+00,  4.6503e+00],\n",
      "        [-3.5388e-01, -6.9992e+00, -2.6274e+00,  2.7147e+00,  8.6868e+00],\n",
      "        [-8.8306e-01, -3.3144e+00, -2.7135e+00,  1.3852e+00,  1.2870e+01],\n",
      "        [ 3.6597e+00, -6.0497e+00, -2.7482e+00,  2.8321e+00, -3.6956e+00],\n",
      "        [-9.1287e-01, -7.6216e+00, -2.7417e+00,  2.2879e+00,  2.4067e+00],\n",
      "        [-1.0992e+00, -9.3922e+00, -2.1573e+00,  1.8416e+00, -2.6598e+00],\n",
      "        [-1.0992e+00, -9.8675e+00, -2.4517e+00,  3.4004e+00, -5.1318e+00],\n",
      "        [-1.0992e+00, -1.0130e+01, -1.7110e+00,  1.9338e+00, -4.4820e+00],\n",
      "        [-1.0992e+00, -1.0113e+01, -1.5583e+00, -5.0479e-01,  7.4284e+00],\n",
      "        [-1.0992e+00, -1.1937e+01, -1.6583e+00, -3.7446e+00,  1.4767e+00],\n",
      "        [-1.0992e+00, -1.1255e+01, -1.6611e+00, -2.9819e+00, -5.7427e+00],\n",
      "        [-1.0992e+00, -8.0050e+00, -2.3257e+00, -8.8349e-01, -5.9758e+00],\n",
      "        [-1.0992e+00, -5.8579e+00, -2.6454e+00,  3.4470e+00, -1.3366e+00],\n",
      "        [-1.0992e+00, -7.4409e+00, -2.0179e+00,  2.3390e+00, -1.1165e+00],\n",
      "        [-1.0992e+00, -9.8174e+00, -2.0221e+00,  3.0032e+00, -5.9875e+00],\n",
      "        [-1.0992e+00, -1.0124e+01, -1.4270e+00,  2.6355e+00, -5.9569e+00],\n",
      "        [-9.5387e-01, -7.4341e+00, -2.6078e+00,  3.2037e+00, -3.7627e+00],\n",
      "        [-9.6505e-01, -6.1508e+00, -2.5276e+00,  3.9248e+00, -5.2848e+00]]), 'x_d_1h': tensor([[-2.2440e-01, -1.2992e+00, -6.1876e-01,  7.4128e-01, -1.3246e+00],\n",
      "        [-2.2440e-01, -1.2197e+00, -6.1876e-01,  2.9962e-01, -1.4111e+00],\n",
      "        [-2.2440e-01, -1.3535e+00, -6.1876e-01,  1.1988e-01, -1.3188e+00],\n",
      "        [-2.2440e-01, -1.1904e+00, -6.1876e-01, -1.6848e-04, -1.2496e+00],\n",
      "        [-2.2440e-01, -1.3145e+00, -6.1876e-01,  6.4668e-02, -1.1573e+00],\n",
      "        [-2.2440e-01, -1.2671e+00, -6.1876e-01,  2.7266e-01, -9.6702e-01],\n",
      "        [-2.2440e-01, -1.2838e+00, -6.1876e-01,  2.4891e-01, -9.6702e-01],\n",
      "        [-2.2440e-01, -1.3800e+00, -5.7012e-01,  2.9513e-01, -9.0359e-01],\n",
      "        [-2.2440e-01, -1.1988e+00, -1.0336e-01,  2.2644e-01, -1.1746e+00],\n",
      "        [-2.2440e-01, -1.0677e+00,  4.4151e-01,  1.9498e-01, -1.4572e+00],\n",
      "        [-2.2440e-01, -1.0133e+00,  8.1041e-01,  2.4441e-01, -1.4514e+00],\n",
      "        [-2.2440e-01, -8.0836e-01,  9.4177e-01,  1.1217e-01, -1.0074e+00],\n",
      "        [-2.2440e-01, -6.1455e-01,  8.4976e-01, -9.8386e-02, -4.9414e-01],\n",
      "        [-2.2440e-01, -6.7311e-01,  5.7249e-01, -2.0238e-01,  1.2867e-01],\n",
      "        [-2.2440e-01, -7.9581e-01,  8.9410e-02, -2.6593e-01,  5.3705e-02],\n",
      "        [-2.2440e-01, -9.8125e-01, -4.5310e-01, -1.8441e-01, -1.5390e-01],\n",
      "        [-2.2440e-01, -1.1458e+00, -6.1876e-01,  1.0062e-01, -4.4224e-01],\n",
      "        [-2.2440e-01, -1.2950e+00, -6.1876e-01,  4.6589e-01, -6.5561e-01],\n",
      "        [-2.2440e-01, -1.3019e+00, -6.1876e-01,  6.7131e-01, -4.2494e-01],\n",
      "        [-2.2440e-01, -1.3229e+00, -6.1876e-01,  7.1239e-01, -1.3660e-01],\n",
      "        [-2.2440e-01, -1.4023e+00, -6.1876e-01,  7.1945e-01,  1.9104e-02],\n",
      "        [-2.2440e-01, -1.4037e+00, -6.1876e-01,  7.1239e-01,  1.3337e-02],\n",
      "        [-2.2440e-01, -1.4009e+00, -6.1876e-01,  7.3679e-01, -4.0187e-01],\n",
      "        [-2.2440e-01, -1.3675e+00, -6.1876e-01,  6.0519e-01, -4.5377e-01],\n",
      "        [-2.2440e-01, -1.3884e+00, -6.1876e-01,  4.6974e-01, -2.9230e-01],\n",
      "        [-2.2440e-01, -1.3842e+00, -6.1876e-01,  4.7744e-01, -2.7500e-01],\n",
      "        [-2.2440e-01, -1.4121e+00, -6.1876e-01,  4.8129e-01, -1.4813e-01],\n",
      "        [-2.2440e-01, -1.4469e+00, -6.1876e-01,  5.3522e-01, -2.0003e-01],\n",
      "        [-2.2440e-01, -1.5139e+00, -6.1876e-01,  6.3215e-01, -1.0777e-01],\n",
      "        [-2.2440e-01, -1.5878e+00, -6.1876e-01,  7.1047e-01, -3.7304e-01],\n",
      "        [-2.2440e-01, -1.6394e+00, -6.1876e-01,  7.0662e-01, -2.3464e-01],\n",
      "        [-2.2440e-01, -1.6463e+00, -5.6535e-01,  7.0341e-01, -3.0960e-01],\n",
      "        [-2.2440e-01, -1.6184e+00, -9.0048e-02,  6.8607e-01, -4.0187e-01],\n",
      "        [-2.2440e-01, -1.5850e+00,  4.6148e-01,  5.9171e-01, -2.0003e-01],\n",
      "        [-2.2440e-01, -1.5264e+00,  8.1991e-01,  5.1531e-01, -5.5181e-01],\n",
      "        [-2.2440e-01, -1.5153e+00,  8.4970e-01,  4.9606e-01, -8.5168e-01],\n",
      "        [-2.2440e-01, -1.5083e+00,  7.1953e-01,  4.7872e-01, -8.7475e-01],\n",
      "        [-2.2440e-01, -1.5125e+00,  4.6287e-01,  4.6396e-01, -1.0074e+00],\n",
      "        [-2.2440e-01, -1.5710e+00,  1.6993e-02,  4.9220e-01, -8.3438e-01],\n",
      "        [-2.2440e-01, -1.6073e+00, -4.7108e-01,  5.4934e-01, -8.9782e-01],\n",
      "        [-2.2440e-01, -1.6770e+00, -6.1876e-01,  5.7758e-01, -9.4972e-01],\n",
      "        [-2.2440e-01, -1.6826e+00, -6.1876e-01,  6.0583e-01, -8.8052e-01],\n",
      "        [-2.2440e-01, -1.6909e+00, -6.1876e-01,  6.1995e-01, -9.7855e-01],\n",
      "        [-2.2440e-01, -1.7314e+00, -6.1876e-01,  6.1610e-01, -9.3242e-01],\n",
      "        [-2.2440e-01, -1.7481e+00, -6.1876e-01,  6.2124e-01, -8.5168e-01],\n",
      "        [-2.2440e-01, -1.7858e+00, -6.1876e-01,  6.0904e-01, -1.0939e+00],\n",
      "        [-2.2440e-01, -1.7885e+00, -6.1876e-01,  5.9748e-01, -8.9205e-01],\n",
      "        [-2.2440e-01, -1.8694e+00, -6.1876e-01,  6.0840e-01, -9.0935e-01],\n",
      "        [-2.2440e-01, -1.8234e+00, -6.1876e-01,  6.1546e-01, -6.9598e-01],\n",
      "        [-2.2440e-01, -1.8290e+00, -6.1876e-01,  6.1803e-01, -8.5745e-01],\n",
      "        [-2.2440e-01, -1.8081e+00, -6.1876e-01,  6.2188e-01, -9.4395e-01],\n",
      "        [-2.2440e-01, -1.7816e+00, -6.1876e-01,  6.2830e-01, -8.9782e-01],\n",
      "        [-2.2440e-01, -1.7607e+00, -6.1876e-01,  6.2958e-01, -8.6898e-01],\n",
      "        [-2.2440e-01, -1.7523e+00, -6.1876e-01,  6.2252e-01, -8.2285e-01],\n",
      "        [-2.2440e-01, -1.7621e+00, -6.1876e-01,  6.1546e-01, -4.3071e-01],\n",
      "        [-2.2440e-01, -1.7579e+00, -5.9621e-01,  6.5269e-01, -7.7095e-01],\n",
      "        [-2.2440e-01, -1.7579e+00, -2.6253e-01,  6.4756e-01, -6.3255e-01],\n",
      "        [-2.2440e-01, -1.7160e+00, -1.2934e-01,  6.0326e-01, -6.4408e-01],\n",
      "        [-2.2440e-01, -1.6896e+00, -1.4824e-01,  5.9684e-01, -7.1905e-01],\n",
      "        [-2.2440e-01, -1.6282e+00,  4.7646e-02,  6.0134e-01, -3.2690e-01],\n",
      "        [-2.2440e-01, -1.6087e+00,  1.2624e-01,  6.1738e-01, -5.1144e-01],\n",
      "        [-2.2440e-01, -1.6101e+00,  5.8113e-02,  6.2445e-01, -2.6347e-01],\n",
      "        [-2.2440e-01, -1.6045e+00, -2.2280e-01,  6.2958e-01, -3.4997e-01],\n",
      "        [-2.2440e-01, -1.6296e+00, -4.8670e-01,  6.4370e-01, -4.0764e-01],\n",
      "        [-2.2440e-01, -1.6756e+00, -6.1876e-01,  6.5719e-01, -2.8654e-01],\n",
      "        [-2.2440e-01, -1.6798e+00, -6.1876e-01,  6.7002e-01, -2.5770e-01],\n",
      "        [-2.2440e-01, -1.7676e+00, -6.1876e-01,  6.9185e-01, -4.0764e-01],\n",
      "        [-2.2440e-01, -1.7858e+00, -6.1876e-01,  7.1432e-01, -7.8248e-01],\n",
      "        [-2.2440e-01, -1.7467e+00, -6.1876e-01,  7.2331e-01, -7.3635e-01],\n",
      "        [-2.2440e-01, -1.7356e+00, -6.1876e-01,  7.2716e-01, -9.3242e-01],\n",
      "        [-2.2440e-01, -1.7244e+00, -6.1876e-01,  7.3614e-01, -1.1054e+00],\n",
      "        [-2.2440e-01, -1.8429e+00, -6.1876e-01,  7.3807e-01, -1.0305e+00],\n",
      "        [-2.2440e-01, -1.8792e+00, -6.1876e-01,  7.2973e-01, -1.1054e+00],\n",
      "        [-2.2440e-01, -1.9085e+00, -6.1876e-01,  7.3229e-01, -1.2150e+00],\n",
      "        [-2.2440e-01, -1.8903e+00, -6.1876e-01,  7.4321e-01, -1.0766e+00],\n",
      "        [-2.2440e-01, -1.8917e+00, -6.1876e-01,  7.4898e-01, -1.0997e+00],\n",
      "        [-2.2440e-01, -1.8875e+00, -6.1876e-01,  7.4898e-01, -1.2784e+00],\n",
      "        [-2.2440e-01, -1.8778e+00, -6.1876e-01,  7.4513e-01, -1.3707e+00],\n",
      "        [-2.0614e-01, -1.8401e+00, -6.1876e-01,  7.4513e-01, -1.4399e+00],\n",
      "        [-2.2440e-01, -1.7997e+00, -5.9820e-01,  7.4642e-01, -1.3822e+00],\n",
      "        [-2.2440e-01, -1.7704e+00, -2.0697e-01,  7.6311e-01, -1.4630e+00],\n",
      "        [-2.2440e-01, -1.6631e+00,  7.5023e-02,  7.7338e-01, -1.5091e+00],\n",
      "        [-2.2440e-01, -1.3926e+00,  1.6403e-02,  7.9713e-01, -1.4860e+00],\n",
      "        [-2.2440e-01, -1.3480e+00, -1.7680e-01,  8.2859e-01, -1.2381e+00],\n",
      "        [-2.2440e-01, -1.3340e+00, -2.7702e-01,  8.4271e-01, -1.2900e+00],\n",
      "        [-2.2440e-01, -1.2838e+00, -3.5889e-01,  8.5298e-01, -1.3015e+00],\n",
      "        [-2.2440e-01, -1.2727e+00, -4.3984e-01,  8.5298e-01, -1.3188e+00],\n",
      "        [-2.2440e-01, -1.2810e+00, -5.6969e-01,  8.7673e-01, -1.5783e+00],\n",
      "        [-2.2440e-01, -1.2727e+00, -6.1876e-01,  9.0177e-01, -1.3822e+00],\n",
      "        [-2.2440e-01, -1.3005e+00, -6.1876e-01,  9.1910e-01, -1.4053e+00],\n",
      "        [-2.2440e-01, -1.2950e+00, -6.1876e-01,  9.3130e-01, -1.3938e+00],\n",
      "        [-2.2440e-01, -1.2741e+00, -6.1876e-01,  9.3579e-01, -1.3707e+00],\n",
      "        [-2.2440e-01, -1.2838e+00, -6.1876e-01,  9.4542e-01, -1.2727e+00],\n",
      "        [-2.2440e-01, -1.3382e+00, -6.1876e-01,  9.5569e-01, -1.2900e+00],\n",
      "        [-2.2440e-01, -1.3145e+00, -6.1876e-01,  9.5890e-01, -9.8432e-01],\n",
      "        [-2.2440e-01, -1.3173e+00, -6.1876e-01,  9.5056e-01, -8.7475e-01]]), 'x_s': tensor([ 0.7071, -0.7071,  0.7071,  0.7071, -0.7071,  0.7071,  0.7071, -0.7071,\n",
      "         0.0000,  0.0000, -0.7071,  0.7071, -0.7071,  0.7071,  0.7071,  0.0000,\n",
      "        -0.7071]), 'y_obs': tensor([[-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877],\n",
      "        [-0.4877]]), 'basin_std': tensor([[0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818],\n",
      "        [0.0818]]), 'basin': array('DEB11190', dtype='<U8'), 'date': array(['2002-01-16T01:00:00.000000000', '2002-01-16T02:00:00.000000000',\n",
      "       '2002-01-16T03:00:00.000000000', '2002-01-16T04:00:00.000000000',\n",
      "       '2002-01-16T05:00:00.000000000', '2002-01-16T06:00:00.000000000',\n",
      "       '2002-01-16T07:00:00.000000000', '2002-01-16T08:00:00.000000000',\n",
      "       '2002-01-16T09:00:00.000000000', '2002-01-16T10:00:00.000000000',\n",
      "       '2002-01-16T11:00:00.000000000', '2002-01-16T12:00:00.000000000',\n",
      "       '2002-01-16T13:00:00.000000000', '2002-01-16T14:00:00.000000000',\n",
      "       '2002-01-16T15:00:00.000000000', '2002-01-16T16:00:00.000000000',\n",
      "       '2002-01-16T17:00:00.000000000', '2002-01-16T18:00:00.000000000',\n",
      "       '2002-01-16T19:00:00.000000000', '2002-01-16T20:00:00.000000000',\n",
      "       '2002-01-16T21:00:00.000000000', '2002-01-16T22:00:00.000000000',\n",
      "       '2002-01-16T23:00:00.000000000', '2002-01-17T00:00:00.000000000'],\n",
      "      dtype='datetime64[ns]')}\n"
     ]
    }
   ],
   "source": [
    "# Check the one train sample\n",
    "dataset_sample = training_dataset[0]\n",
    "print(f\"One sample in training dataset look like: {dataset_sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader training\n",
    "train_loader = DataLoader(\n",
    "    dataset=training_dataset,\n",
    "    batch_size=model_configuration[\"batch_size_training\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=training_dataset.collate_fn,\n",
    ")\n",
    "\n",
    "# Print details of a loader´s sample to see that our format is correct\n",
    "print(\"Number of batches in training: \", len(train_loader))\n",
    "print(\"\\nSample batch details:\")\n",
    "print(f\"{'Key':<12} | {'Shape':<20}\")\n",
    "print(\"-\" * 35)\n",
    "# Loop through the sample dictionary and print the shape of each element\n",
    "for key, value in next(iter(train_loader)).items():\n",
    "    print(f\"{key:<12} | {str(value.shape):<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create dataset for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In evaluation (validation and testing) we will create an individual dataset per basin. This will give us more \n",
    "# flexibility\n",
    "entities_ids = np.loadtxt(path_entities, dtype=\"str\").tolist()\n",
    "entities_ids = [entities_ids] if isinstance(entities_ids, str) else entities_ids\n",
    "validation_dataset = {}\n",
    "for entity in entities_ids:\n",
    "    dataset = Datasetclass(\n",
    "        dynamic_input=dynamic_input,\n",
    "        target=target,\n",
    "        sequence_length=model_configuration[\"seq_length\"],\n",
    "        time_period=validation_period,\n",
    "        path_data=path_data,\n",
    "        entity=entity,\n",
    "        check_NaN=False,\n",
    "        predict_last_n=model_configuration[\"predict_last_n_evaluation\"],\n",
    "        static_input=static_input,\n",
    "        custom_freq_processing=model_configuration[\"custom_freq_processing\"],\n",
    "        dynamic_embedding=model_configuration[\"dynamic_embeddings\"],\n",
    "        unique_prediction_blocks=model_configuration[\"unique_prediction_blocks_evaluation\"],\n",
    "    )\n",
    "\n",
    "    dataset.scaler = training_dataset.scaler\n",
    "    dataset.standardize_data(standardize_output=False)\n",
    "    validation_dataset[entity] = dataset\n",
    "    \n",
    "total_sequences = sum(len(dataset) for dataset in validation_dataset.values())\n",
    "print(f\"Total number of validation sequences: {total_sequences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the val dataset\n",
    "# dataset = validation_dataset[entities_ids[0]]\n",
    "# print(f\"basin {entities_ids[0]}, dataset length: {len(dataset)} samples\")\n",
    "# print(f\"the first sample of basin {entities_ids[0]} in val dataset is: {dataset[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct model\n",
    "set_random_seed(seed=seed)\n",
    "model = modelclass(model_configuration=model_configuration).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = Optimizer(model=model, model_configuration=model_configuration)\n",
    "\n",
    "# set forget gate to 3 to ensure that the model is capable to learn long term dependencies\n",
    "model.lstm.bias_hh_l0.data[model_configuration[\"hidden_size\"] : 2 * model_configuration[\"hidden_size\"]] = (\n",
    "    model_configuration[\"set_forget_gate\"]\n",
    ")\n",
    "\n",
    "# Define the initail val_nse for selecting the best epoch during validation\n",
    "best_val_nse = float(\"-inf\")  # Best NSE so far\n",
    "best_epoch = -1\n",
    "best_model_state = None\n",
    "NSE_basins_at_best_epoch = []\n",
    "\n",
    "training_time = time.time()\n",
    "# Loop through the different epochs\n",
    "for epoch in range(1, model_configuration[\"no_of_epochs\"] + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    total_loss = []\n",
    "    # Training -------------------------------------------------------------------------------------------------------\n",
    "    model.train()\n",
    "    for idx, sample in enumerate(train_loader):\n",
    "        # maximum iterations per epoch\n",
    "        if (\n",
    "            model_configuration.get(\"max_updates_per_epoch\") is not None\n",
    "            and idx >= model_configuration[\"max_updates_per_epoch\"]\n",
    "        ):\n",
    "            break\n",
    "        sample = upload_to_device(sample, device)  # upload tensors to device\n",
    "        optimizer.optimizer.zero_grad()  # sets gradients of weigths and bias to zero\n",
    "        pred = model(sample)  # forward call\n",
    "\n",
    "        loss = nse_basin_averaged(y_sim=pred[\"y_hat\"], y_obs=sample[\"y_obs\"], per_basin_target_std=sample[\"basin_std\"])\n",
    "\n",
    "        loss.backward()  # backpropagates\n",
    "\n",
    "        optimizer.clip_grad_and_step(epoch, idx)  # clip gradients and update weights\n",
    "\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        # remove from cuda\n",
    "        del sample, pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # training report\n",
    "    report = f\"Epoch: {epoch:<2} | Loss training: {'%.3f ' % (np.mean(total_loss))}\"\n",
    "\n",
    "    # Validation -----------------------------------------------------------------------------------------------------\n",
    "    if epoch % model_configuration[\"validate_every\"] == 0:\n",
    "        model.eval()\n",
    "        validation_results = {}\n",
    "        with torch.no_grad():\n",
    "            # If we define validate_n_random_basins as 0 or negative, we take all the basins\n",
    "            if model_configuration[\"validate_n_random_basins\"] <= 0:\n",
    "                validation_basin_ids = validation_dataset.keys()\n",
    "            else:\n",
    "                keys = list(validation_dataset.keys())\n",
    "                validation_basin_ids = random.sample(keys, model_configuration[\"validate_n_random_basins\"])\n",
    "\n",
    "            # go through each basin that will be used for validation\n",
    "            for basin in validation_basin_ids:\n",
    "                loader = DataLoader(\n",
    "                    dataset=validation_dataset[basin],\n",
    "                    batch_size=model_configuration[\"batch_size_evaluation\"],\n",
    "                    shuffle=False,\n",
    "                    drop_last=False,\n",
    "                    collate_fn=validation_dataset[basin].collate_fn,\n",
    "                )\n",
    "\n",
    "                df_ts = pd.DataFrame()\n",
    "                for sample in loader:\n",
    "                    sample = upload_to_device(sample, device)\n",
    "                    pred = model(sample)\n",
    "                    # backtransformed information\n",
    "                    y_sim = pred[\"y_hat\"] * validation_dataset[basin].scaler[\"y_std\"].to(device) + validation_dataset[\n",
    "                        basin\n",
    "                    ].scaler[\"y_mean\"].to(device)\n",
    "\n",
    "                    # join results in a dataframe and store them in a dictionary (is easier to plot later)\n",
    "                    df = pd.DataFrame(\n",
    "                        {\n",
    "                            \"y_obs\": sample[\"y_obs\"].flatten().cpu().detach(),\n",
    "                            \"y_sim\": y_sim[:, -model_configuration[\"predict_last_n_evaluation\"] :, :]\n",
    "                            .flatten()\n",
    "                            .cpu()\n",
    "                            .detach(),\n",
    "                        },\n",
    "                        index=pd.to_datetime(sample[\"date\"].flatten()),\n",
    "                    )\n",
    "\n",
    "                    df_ts = pd.concat([df_ts, df], axis=0)\n",
    "\n",
    "                    # remove from cuda\n",
    "                    del sample, pred, y_sim\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                validation_results[basin] = df_ts\n",
    "\n",
    "            # average loss validation \n",
    "            # loss_validation is the median NSE of all basins in validation set\n",
    "            loss_validation = nse(df_results=validation_results)\n",
    "            report += f\"| NSE validation: {'%.3f ' % (loss_validation)}\"\n",
    "            # calculate NSE for all basins\n",
    "            NSE_basins = nse(df_results=validation_results, average=False)\n",
    "\n",
    "    # save model after every epoch\n",
    "    weight_path = weights_save_path + \"/epoch_\" + str(epoch)\n",
    "    torch.save(model.state_dict(), weight_path)\n",
    "\n",
    "    # print epoch report\n",
    "    report += (\n",
    "        f\"| Epoch time: {'%.1f ' % (time.time() - epoch_start_time)} s | \"\n",
    "        f\"LR:{'%.5f ' % (optimizer.optimizer.param_groups[0]['lr'])}\"\n",
    "    )\n",
    "    print(report)\n",
    "    write_report(file_path=path_save_folder + \"/run_progress.txt\", text=report)\n",
    "    # modify learning rate\n",
    "    optimizer.update_optimizer_lr(epoch=epoch)\n",
    "    \n",
    "    # Save and update best model after each epoch\n",
    "    if loss_validation > best_val_nse:\n",
    "        best_val_nse = loss_validation\n",
    "        best_epoch = epoch\n",
    "        best_model_state= model.state_dict()\n",
    "        NSE_basins_at_best_epoch = NSE_basins\n",
    "        torch.save(best_model_state, path_save_folder + \"/best_model\")\n",
    "        \n",
    "\n",
    "if best_epoch is not None:\n",
    "    # torch.save(best_model_state, path_save_folder + \"/best_model\")\n",
    "    best_epoch_report = f\"Best (validation) median NSE: {best_val_nse:.3f} at epoch {best_epoch}\"\n",
    "else:\n",
    "    best_epoch_report = \"No best model was selected (best_model_state is None).\"\n",
    "\n",
    "# Save NSE for all basins in validation set using the best epoch model in a csv file\n",
    "df_NSE = pd.DataFrame(data={\"basin_id\": validation_results.keys(), \"NSE\": np.round(NSE_basins_at_best_epoch, 3)})\n",
    "df_NSE = df_NSE.set_index(\"basin_id\")\n",
    "df_NSE.to_csv(os.path.join(path_save_folder, \"NSE_val.csv\"), index=True, header=True)\n",
    "mean_nse = df_NSE[\"NSE\"].mean()\n",
    "\n",
    "# print final report\n",
    "report = (\n",
    "    f\"{best_epoch_report}\\n\"\n",
    "    f\"The mean NSE (validation) of this epoch model is {'%.2f ' % mean_nse}\\n\"\n",
    "    f\"Total training time: {'%.1f ' % ((time.time() - training_time)/60)} min\"\n",
    ")\n",
    "print(report)\n",
    "write_report(file_path=path_save_folder + \"/run_progress.txt\", text=report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"***************  Evaluation process begin  ****************\")\n",
    "\n",
    "# In case I already trained an LSTM I can re-construct the model\n",
    "model = modelclass(model_configuration=model_configuration).to(device)\n",
    "model.load_state_dict(torch.load(path_save_folder + \"/best_model\", map_location=device))\n",
    "\n",
    "test_result_save_path = os.path.join(path_save_folder, \"test_results\")\n",
    "if not os.path.exists(test_result_save_path):\n",
    "    os.makedirs(test_result_save_path)\n",
    "\n",
    "# We can read the training scaler or read a previously stored one\n",
    "# scaler = training_dataset.scaler\n",
    "with open(path_save_folder + \"/scaler.pickle\", \"rb\") as file:\n",
    "   scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In evaluation (validation and testing) we will create an individual dataset per basin. This will give us more \n",
    "# flexibility\n",
    "entities_ids = np.loadtxt(path_entities, dtype=\"str\").tolist()\n",
    "entities_ids = [entities_ids] if isinstance(entities_ids, str) else entities_ids\n",
    "testing_dataset = {}\n",
    "for entity in entities_ids:\n",
    "    dataset = Datasetclass(\n",
    "        dynamic_input=dynamic_input,\n",
    "        target=target,\n",
    "        sequence_length=model_configuration[\"seq_length\"],\n",
    "        time_period=testing_period,\n",
    "        path_data=path_data,\n",
    "        entity=entity,\n",
    "        check_NaN=False,\n",
    "        predict_last_n=model_configuration[\"predict_last_n_evaluation\"],\n",
    "        static_input=static_input,\n",
    "        custom_freq_processing=model_configuration[\"custom_freq_processing\"],\n",
    "        dynamic_embedding=model_configuration[\"dynamic_embeddings\"],\n",
    "        unique_prediction_blocks=model_configuration[\"unique_prediction_blocks_evaluation\"]\n",
    "    )\n",
    "\n",
    "    dataset.scaler = scaler\n",
    "    dataset.standardize_data(standardize_output=False)\n",
    "    testing_dataset[entity] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the test dataset\n",
    "# dataset = testing_dataset[entities_ids[0]]\n",
    "# print(f\"basin {entities_ids[0]}, dataset length: {len(dataset)} samples\")\n",
    "# print(f\"the first sample of basin {entities_ids[0]} in test dataset is: {dataset[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_start_time = time.time()\n",
    "\n",
    "model.eval()\n",
    "test_results = {}\n",
    "with torch.no_grad():\n",
    "    for basin, dataset in testing_dataset.items():\n",
    "        loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=model_configuration[\"batch_size_evaluation\"],\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            collate_fn=testing_dataset[basin].collate_fn,\n",
    "        )\n",
    "\n",
    "        df_ts = pd.DataFrame()\n",
    "        for sample in loader:\n",
    "            sample = upload_to_device(sample, device)  # upload tensors to device\n",
    "            pred = model(sample)\n",
    "            # backtransformed information\n",
    "            y_sim = pred[\"y_hat\"] * dataset.scaler[\"y_std\"].to(device) + dataset.scaler[\"y_mean\"].to(device)\n",
    "\n",
    "            # join results in a dataframe and store them in a dictionary (is easier to plot later)\n",
    "            df = pd.DataFrame(\n",
    "                {\n",
    "                    \"y_obs\": sample[\"y_obs\"].flatten().cpu().detach(),\n",
    "                    \"y_sim\": y_sim[:, -model_configuration[\"predict_last_n_evaluation\"] :, :].flatten().cpu().detach(),\n",
    "                },\n",
    "                index=pd.to_datetime(sample[\"date\"].flatten()),\n",
    "            )\n",
    "\n",
    "            df_ts = pd.concat([df_ts, df], axis=0)\n",
    "\n",
    "            # remove from cuda\n",
    "            del sample, pred, y_sim\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        test_results[basin] = df_ts\n",
    "\n",
    "# Save results as a pickle file\n",
    "with open(test_result_save_path + \"/test_results.pickle\", \"wb\") as f:\n",
    "    pickle.dump(test_results, f)\n",
    "\n",
    "evaluation_time = (time.time() - eval_start_time) / 60 # min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss testing\n",
    "loss_testing = nse(df_results=test_results, average=False)\n",
    "df_NSE = pd.DataFrame(data={\"basin_id\": test_results.keys(), \"NSE\": np.round(loss_testing, 3)})\n",
    "df_NSE = df_NSE.set_index(\"basin_id\")\n",
    "\n",
    "# Save the NSE for each basin in a csv file\n",
    "df_NSE.to_csv(os.path.join(test_result_save_path, \"NSE_testing.csv\"), index=True, header=True)\n",
    "mean_nse = df_NSE[\"NSE\"].mean()\n",
    "median_nse = df_NSE[\"NSE\"].median()\n",
    "\n",
    "# print evaluation report\n",
    "report = (\n",
    "    f\"Median NSE across all basins (test dataset): {median_nse:.3f}\\n\"\n",
    "    f\"Mean NSE across all basins (test dataset): {mean_nse:.3f}\\n\"\n",
    "    f\"Total evaluation time: {'%.1f ' % evaluation_time} min\"\n",
    ")\n",
    "print(report)\n",
    "write_report(file_path=path_save_folder + \"/run_progress.txt\", text=report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "plt.hist(df_NSE[\"NSE\"], bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "# Add NSE statistics to the plot\n",
    "plt.text(\n",
    "    0.01,\n",
    "    0.8,\n",
    "    (\n",
    "        f'Mean: {\"%.2f\" % df_NSE[\"NSE\"].mean():>7}\\n'\n",
    "        f'Median: {\"%.2f\" % df_NSE[\"NSE\"].median():>0}\\n'\n",
    "        f'Max: {\"%.2f\" % df_NSE[\"NSE\"].max():>9}\\n'\n",
    "        f'Min: {\"%.2f\" % df_NSE[\"NSE\"].min():>10}'\n",
    "    ),\n",
    "    transform=plt.gca().transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    ")\n",
    "\n",
    "# Format plot\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "plt.xlabel(\"NSE\", fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Frequency\", fontsize=12, fontweight=\"bold\")\n",
    "plt.title(\"NSE Histogram\", fontsize=16, fontweight=\"bold\")\n",
    "plt.savefig(os.path.join(test_result_save_path, \"NSE_Histogram.png\"), bbox_inches=\"tight\", pad_inches=0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot simulated and observed discharges\n",
    "# basin_to_analyze = \"DE210300\"\n",
    "\n",
    "# # colorblind friendly palette\n",
    "# color_palette = {\"observed\": \"#377eb8\", \"simulated\": \"#4daf4a\"}\n",
    "\n",
    "# # (1) Output time window of test dataset period\n",
    "# plt.plot(test_results[basin_to_analyze][\"y_obs\"], label=\"observed\", color=color_palette[\"observed\"])\n",
    "# plt.plot(test_results[basin_to_analyze][\"y_sim\"], label=\"simulated\", alpha=0.5, color=color_palette[\"simulated\"])\n",
    "\n",
    "# # # (2) Output custom time window\n",
    "# # start_date = \"2019-01-01 01:00:00\"\n",
    "# # end_date = \"2019-02-01 01:00:00\"\n",
    "# # plt.plot(test_results[basin_to_analyze][\"y_obs\"][start_date:end_date], label=\"observed\", color=color_palette[\"observed\"])\n",
    "# # plt.plot(test_results[basin_to_analyze][\"y_sim\"][start_date:end_date], label=\"simulated\", alpha=0.5, color=color_palette[\"simulated\"])\n",
    "\n",
    "# # Format plot\n",
    "# plt.xlabel(\"Date\", fontsize=12, fontweight=\"bold\")\n",
    "# plt.ylabel(\"Discharge [mm/d]\", fontsize=12, fontweight=\"bold\")\n",
    "# plt.title(f\"Result comparison (basin {basin_to_analyze})\", fontsize=16, fontweight=\"bold\")\n",
    "# plt.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "# plt.legend(loc=\"upper right\", fontsize=12)\n",
    "# plt.savefig(os.path.join(test_result_save_path, f\"Result comparison (basin {basin_to_analyze}).png\"), bbox_inches=\"tight\", pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m111"
  },
  "kernelspec": {
   "display_name": "HY3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
