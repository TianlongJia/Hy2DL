{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the median NSE by ensemble of LSTMs\n",
    "\n",
    "e.g., the model is trained for 10 times. \n",
    "\n",
    "(1) we calculate the median simulated discharge of 10 runs for each basin, \n",
    "\n",
    "(2) calculate NSE for each basin using the calculated median simulated discharge,\n",
    "\n",
    "(3) calculate median NSE across all basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from hy2dl.aux_functions.functions_evaluation import nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the results generated using Hy2DL\n",
    "path_results_LSTM = [\"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/28_days_seed_110/test_results_best_epoch/\",\n",
    "                     \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/28_days_seed_111/test_results_best_epoch/\",\n",
    "                     \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/28_days_seed_222/test_results_best_epoch/\",\n",
    "                     \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/28_days_seed_333/test_results_best_epoch/\",\n",
    "                     \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/28_days_seed_444/test_results_best_epoch/\",\n",
    "                     \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/28_days_seed_555/test_results_best_epoch/\",\n",
    "                     \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/28_days_seed_666/test_results_best_epoch/\",\n",
    "                     \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/28_days_seed_777/test_results_best_epoch/\",\n",
    "                     \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/28_days_seed_888/test_results_best_epoch/\",\n",
    "                     \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/28_days_seed_999/test_results_best_epoch/\"\n",
    "                     ]\n",
    "\n",
    "test_result_save_path = \"/hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/Ensemble/\"\n",
    "csv_name = \"28_day.csv\"\n",
    "\n",
    "if not os.path.exists(test_result_save_path):\n",
    "    os.makedirs(test_result_save_path)\n",
    "\n",
    "    \n",
    "# Read information produced by ensemble of LSTMs and store it in dictionary of dataframes\n",
    "lstm_results = {}\n",
    "for i, ensemble_member in enumerate(path_results_LSTM):\n",
    "    with open(ensemble_member + \"/test_results.pickle\", \"rb\") as f:\n",
    "        info_lstm = pickle.load(f)\n",
    "    # Iterate over each basin\n",
    "    for basin in info_lstm.keys():\n",
    "        y_sim = info_lstm[basin][\"y_sim\"]\n",
    "        if i == 0: # If this is the first ensemble member, initialize the DataFrame with y_obs and y_sim\n",
    "            y_obs = info_lstm[basin][\"y_obs\"]\n",
    "            lstm_results[basin] = pd.DataFrame(data={\"y_obs\": y_obs, f\"y_sim_ens_{i+1}\": y_sim}, index=y_obs.index)\n",
    "        else: # For subsequent ensemble members, add y_sim as a new column\n",
    "            lstm_results[basin][f\"y_sim_ens_{i+1}\"] = y_sim\n",
    "            \n",
    "# Calculate the median of the simulated values for each basin and add it as a new column\n",
    "for basin in lstm_results.keys():\n",
    "    # Select only the y_sim columns\n",
    "    y_sim_columns = [col for col in lstm_results[basin].columns if col.startswith(\"y_sim_ens_\")]\n",
    "    lstm_results[basin][\"y_sim\"] = lstm_results[basin][y_sim_columns].median(axis=1)\n",
    "    \n",
    "# Calculate the median NSE across all basins\n",
    "df_NSE_lstm_CAMELS_US_hourly = pd.DataFrame(data={\"basin_id\": list(lstm_results.keys()), \n",
    "                                                  \"Median_NSE_by_ensemble_of_LSTMs\": np.round(nse(df_results=lstm_results, average=False),3)}\n",
    "                                                  ).set_index(\"basin_id\")\n",
    "\n",
    "# print(df_NSE_lstm_CAMELS_US_hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results by ensemble of LSTMs has been saved to /hkfs/home/haicore/iwu/qa8171/Project/Hy2DL/results/US_exp2_correct/Ensemble/\n"
     ]
    }
   ],
   "source": [
    "# Save results by ensemble of LSTMs in a csv file\n",
    "\n",
    "df_NSE_lstm_CAMELS_US_hourly.to_csv(os.path.join(test_result_save_path, csv_name))\n",
    "print(f\"Results by ensemble of LSTMs has been saved to {test_result_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median NSE across all basins: 0.752\n"
     ]
    }
   ],
   "source": [
    "median_NSE = df_NSE_lstm_CAMELS_US_hourly[\"Median_NSE_by_ensemble_of_LSTMs\"].median()\n",
    "print(f\"Median NSE across all basins: {median_NSE:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m111"
  },
  "kernelspec": {
   "display_name": "Python (HY3.9)",
   "language": "python",
   "name": "hy3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
